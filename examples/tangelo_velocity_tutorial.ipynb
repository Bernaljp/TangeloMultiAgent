{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Tangelo Velocity Tutorial: Stage 1 Regulatory Model\n\nThis notebook demonstrates **Tangelo Velocity Stage 1** - a regulatory network model for RNA velocity estimation that integrates chromatin accessibility (ATAC-seq) data with RNA splicing dynamics.\n\n## Overview\n\n**Stage 1** focuses on regulatory modeling and includes:\n- **Sigmoid Feature Transformation**: Learnable smooth feature mapping for RNA expression\n- **Linear Interaction Networks**: Gene regulatory interactions with ATAC masking\n- **ODE Dynamics**: Cell-specific splicing and degradation rate modeling\n- **Regulatory Loss Functions**: Reconstruction and regulatory constraint losses\n\n**What's Implemented (Stage 0 + Stage 1):**\n- Stage 0: MuDataProcessor, GraphBuilder, Node2VecEmbedding\n- Stage 1: SigmoidFeatureModule, LinearInteractionNetwork, VelocityODE, Stage1RegulatoryModel\n\n**Future Stages (not yet implemented):**\n- Stage 2: Graph neural networks for spatial modeling  \n- Stage 3: Integrated multi-modal architecture\n- Stage 4: Advanced features and hierarchical modeling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\n# Deep learning\nimport torch\nimport torch.nn as nn\n\n# Single-cell analysis \nimport scanpy as sc\ntry:\n    import muon as mu\n    import anndata as ad\n    HAS_MUON = True\nexcept ImportError:\n    print(\"Note: muon not available. Using synthetic data for demonstration.\")\n    HAS_MUON = False\n\n# Tangelo Velocity - Stage 1 components\nimport tangelo_velocity as tv\nfrom tangelo_velocity.config import TangeloConfig, get_stage_config\n\n# Configure visualization\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=100, facecolor='white', figsize=(6, 6))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.rcParams['figure.dpi'] = 100\n\nprint(f\"Tangelo Velocity version: {tv.__version__}\")\nprint(f\"Available modules: {[x for x in tv.__all__ if not x.startswith('_')]}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Has GPU: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Stage 1 Configuration\n\nStage 1 focuses on regulatory modeling. Let's start by exploring the configuration options:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get default Stage 1 configuration\nstage1_config = get_stage_config(stage=1)\n\nprint(\"=== Stage 1 Configuration Overview ===\")\nprint(f\"Development Stage: {stage1_config.development_stage}\")\nprint(f\"Gene dimension: {stage1_config.gene_dim} (will be inferred from data)\")\nprint(f\"ATAC dimension: {stage1_config.atac_dim} (will be inferred from data)\")\n\nprint(\"\\n=== Regulatory Configuration ===\")\nprint(f\"Use ATAC masking: {stage1_config.regulatory.use_atac_masking}\")\nprint(f\"ATAC threshold: {stage1_config.regulatory.atac_threshold}\")\nprint(f\"Use sigmoid features: {stage1_config.regulatory.use_sigmoid_features}\")\nprint(f\"Sigmoid components: {stage1_config.regulatory.n_sigmoid_components}\")\nprint(f\"Interaction strength: {stage1_config.regulatory.interaction_strength}\")\n\nprint(\"\\n=== ODE Configuration ===\")\nprint(f\"Solver: {stage1_config.ode.solver}\")\nprint(f\"Tolerance (rtol/atol): {stage1_config.ode.rtol}/{stage1_config.ode.atol}\")\nprint(f\"Time span: {stage1_config.ode.t_span}\")\nprint(f\"Beta range: {stage1_config.ode.init_beta_range}\")\nprint(f\"Gamma range: {stage1_config.ode.init_gamma_range}\")\n\nprint(\"\\n=== Training Configuration ===\")\nprint(f\"Epochs: {stage1_config.training.n_epochs}\")\nprint(f\"Learning rate: {stage1_config.training.learning_rate}\")\nprint(f\"Batch size: {stage1_config.training.batch_size}\")\nprint(f\"Optimizer: {stage1_config.training.optimizer}\")\n\nprint(\"\\n=== Loss Configuration ===\")\nprint(f\"Reconstruction weight: {stage1_config.loss.reconstruction_weight}\")\nprint(f\"L2 regularization: {stage1_config.loss.l2_reg}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_synthetic_stage1_data(n_cells=500, n_genes=200, n_peaks=300):\n    \"\"\"\n    Create synthetic multi-modal data for Stage 1 demonstration.\n    \n    This creates realistic RNA and ATAC data with regulatory relationships\n    suitable for testing the Stage 1 regulatory model.\n    \"\"\"\n    print(f\"Creating synthetic Stage 1 data: {n_cells} cells, {n_genes} genes, {n_peaks} peaks\")\n    \n    # Set random seed for reproducibility\n    np.random.seed(42)\n    torch.manual_seed(42)\n    \n    # Create realistic RNA expression data\n    # Simulate multiple cell types with different expression programs\n    n_programs = 3\n    program_genes = n_genes // n_programs\n    \n    # Base expression levels\n    base_expression = np.random.gamma(2, 2, (n_cells, n_genes))\n    \n    # Add cell type specific programs\n    cell_types = np.random.choice(n_programs, n_cells)\n    for prog in range(n_programs):\n        mask = cell_types == prog\n        gene_start = prog * program_genes\n        gene_end = (prog + 1) * program_genes\n        base_expression[mask, gene_start:gene_end] *= 3  # Upregulate program genes\n    \n    # Create spliced/unspliced from base expression\n    # Simulate splicing dynamics: more unspliced in highly expressed genes\n    splicing_efficiency = np.random.beta(2, 1, n_genes)  # Varies by gene\n    \n    unspliced = base_expression * (1 - splicing_efficiency) + np.random.gamma(1, 0.5, (n_cells, n_genes))\n    spliced = base_expression * splicing_efficiency + np.random.gamma(1, 0.5, (n_cells, n_genes))\n    \n    # Simulate chromatin accessibility \n    # Create gene-peak linkages (regulatory relationships)\n    peak_gene_links = np.random.binomial(1, 0.3, (n_peaks, n_genes))  # 30% linkage probability\n    \n    # ATAC signal correlates with linked gene expression\n    atac_data = np.zeros((n_cells, n_peaks))\n    for peak in range(n_peaks):\n        linked_genes = peak_gene_links[peak, :] > 0\n        if linked_genes.sum() > 0:\n            # Peak accessibility correlates with linked gene expression\n            atac_data[:, peak] = spliced[:, linked_genes].mean(axis=1) * 0.5\n        # Add noise\n        atac_data[:, peak] += np.random.gamma(0.5, 1, n_cells)\n    \n    # Simulate open chromatin (binary accessibility for regulatory masking)\n    open_chromatin = (atac_data > np.percentile(atac_data, 70, axis=0)).astype(float)\n    \n    # Create gene-specific open chromatin signal\n    gene_chromatin = np.zeros((n_cells, n_genes))\n    for gene in range(n_genes):\n        linked_peaks = peak_gene_links[:, gene] > 0\n        if linked_peaks.sum() > 0:\n            gene_chromatin[:, gene] = open_chromatin[:, linked_peaks].mean(axis=1)\n        else:\n            gene_chromatin[:, gene] = np.random.binomial(1, 0.2, n_cells)  # Background accessibility\n    \n    # Create moments for velocity analysis\n    M_s = spliced + np.random.normal(0, 0.1 * spliced)\n    M_u = unspliced + np.random.normal(0, 0.1 * unspliced)\n    \n    print(f\"Created synthetic data with:\")\n    print(f\"  - {n_programs} cell type programs\")\n    print(f\"  - {peak_gene_links.sum()} peak-gene regulatory links\")\n    print(f\"  - {(gene_chromatin > 0.5).sum()} accessible gene-peak pairs\")\n    \n    return {\n        'spliced': spliced.astype(np.float32),\n        'unspliced': unspliced.astype(np.float32), \n        'M_s': M_s.astype(np.float32),\n        'M_u': M_u.astype(np.float32),\n        'gene_chromatin': gene_chromatin.astype(np.float32),\n        'atac_data': atac_data.astype(np.float32),\n        'open_chromatin': open_chromatin.astype(np.float32),\n        'cell_types': cell_types,\n        'peak_gene_links': peak_gene_links.astype(np.float32)\n    }\n\n# Create synthetic data for Stage 1 demo\ndata = create_synthetic_stage1_data(n_cells=500, n_genes=200, n_peaks=300)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the synthetic data\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# RNA expression by cell type\nfor i, cell_type in enumerate(np.unique(data['cell_types'])):\n    mask = data['cell_types'] == cell_type\n    axes[0, 0].scatter(np.log1p(data['spliced'][mask].mean(axis=1)), \n                      np.log1p(data['unspliced'][mask].mean(axis=1)),\n                      label=f'Type {cell_type}', alpha=0.6, s=20)\naxes[0, 0].set_xlabel('Log(Spliced + 1)')\naxes[0, 0].set_ylabel('Log(Unspliced + 1)')\naxes[0, 0].set_title('RNA Expression by Cell Type')\naxes[0, 0].legend()\n\n# Chromatin accessibility distribution\naxes[0, 1].hist(data['gene_chromatin'].mean(axis=0), bins=30, alpha=0.7, \n               label='Gene accessibility', color='orange')\naxes[0, 1].set_xlabel('Mean Accessibility')\naxes[0, 1].set_ylabel('Number of Genes')\naxes[0, 1].set_title('Chromatin Accessibility Distribution')\n\n# Expression vs Accessibility correlation\nexpr_mean = data['spliced'].mean(axis=0)\nchrom_mean = data['gene_chromatin'].mean(axis=0)\ncorrelation = np.corrcoef(expr_mean, chrom_mean)[0, 1]\naxes[0, 2].scatter(expr_mean, chrom_mean, alpha=0.6, s=20)\naxes[0, 2].set_xlabel('Mean Spliced Expression')\naxes[0, 2].set_ylabel('Mean Chromatin Accessibility')\naxes[0, 2].set_title(f'Expression vs Accessibility\\n(r = {correlation:.3f})')\n\n# Splicing efficiency (spliced / (spliced + unspliced))\nsplicing_eff = data['spliced'] / (data['spliced'] + data['unspliced'] + 1e-6)\naxes[1, 0].hist(splicing_eff.mean(axis=0), bins=30, alpha=0.7, color='green')\naxes[1, 0].set_xlabel('Mean Splicing Efficiency')\naxes[1, 0].set_ylabel('Number of Genes')\naxes[1, 0].set_title('Splicing Efficiency Distribution')\n\n# Peak-gene regulatory network\naxes[1, 1].imshow(data['peak_gene_links'][:50, :50], cmap='Blues', aspect='auto')\naxes[1, 1].set_xlabel('Genes (first 50)')\naxes[1, 1].set_ylabel('Peaks (first 50)')\naxes[1, 1].set_title('Peak-Gene Regulatory Links')\n\n# Cell type composition\ncell_counts = np.bincount(data['cell_types'])\naxes[1, 2].pie(cell_counts, labels=[f'Type {i}' for i in range(len(cell_counts))], \n              autopct='%1.1f%%', startangle=90)\naxes[1, 2].set_title('Cell Type Composition')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"=== Data Summary ===\")\nprint(f\"RNA data shape: {data['spliced'].shape}\")\nprint(f\"ATAC data shape: {data['atac_data'].shape}\")\nprint(f\"Gene chromatin shape: {data['gene_chromatin'].shape}\")\nprint(f\"Regulatory links: {data['peak_gene_links'].sum():.0f}\")\nprint(f\"Mean expression: {data['spliced'].mean():.2f}\")\nprint(f\"Mean accessibility: {data['gene_chromatin'].mean():.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Stage 1 Component Demonstration\n\nLet's explore the individual Stage 1 components before building the full model:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import Stage 1 specific components\nif hasattr(tv, 'models'):\n    from tangelo_velocity.models import (\n        SigmoidFeatureModule, \n        LinearInteractionNetwork,\n        VelocityODE,\n        ODEParameterPredictor,\n        ReconstructionLoss,\n        RegulatoryNetworkLoss\n    )\n    \n    print(\"=== Stage 1 Components Available ===\")\n    print(\"✓ SigmoidFeatureModule - Learnable feature transformation\")\n    print(\"✓ LinearInteractionNetwork - Gene regulatory interactions\") \n    print(\"✓ VelocityODE - ODE dynamics modeling\")\n    print(\"✓ ODEParameterPredictor - Cell-specific parameter prediction\")\n    print(\"✓ ReconstructionLoss - RNA abundance matching\")\n    print(\"✓ RegulatoryNetworkLoss - Regulatory constraint loss\")\n    \nelse:\n    print(\"Models module not available - dependencies may be missing\")\n    print(\"This tutorial will demonstrate configuration and concepts only\")\n\n# Convert data to tensors for component testing\nn_cells, n_genes = data['spliced'].shape\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nspliced_tensor = torch.tensor(data['spliced'], dtype=torch.float32, device=device)\nunspliced_tensor = torch.tensor(data['unspliced'], dtype=torch.float32, device=device) \nchromatin_tensor = torch.tensor(data['gene_chromatin'], dtype=torch.float32, device=device)\n\nprint(f\"\\nData loaded on device: {device}\")\nprint(f\"Tensor shapes - Spliced: {spliced_tensor.shape}, Chromatin: {chromatin_tensor.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.1 Sigmoid Feature Module\n\nThe `SigmoidFeatureModule` provides learnable smooth transformations of RNA expression data:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if hasattr(tv, 'models'):\n    # Create sigmoid feature module\n    sigmoid_module = SigmoidFeatureModule(\n        n_genes=n_genes,\n        n_components=10,  # Number of sigmoid components per gene\n        init_a=1.0,       # Initial slope\n        init_b=0.0        # Initial bias\n    ).to(device)\n    \n    print(f\"Sigmoid module parameters: {sum(p.numel() for p in sigmoid_module.parameters())}\")\n    \n    # Apply transformation to spliced data\n    transformed_features = sigmoid_module(spliced_tensor)\n    \n    print(f\"Input shape: {spliced_tensor.shape}\")\n    print(f\"Output shape: {transformed_features.shape}\")\n    print(f\"Input range: [{spliced_tensor.min():.3f}, {spliced_tensor.max():.3f}]\")\n    print(f\"Output range: [{transformed_features.min():.3f}, {transformed_features.max():.3f}]\")\n    \n    # Visualize transformation for first few genes\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    for i in range(3):\n        x_vals = spliced_tensor[:, i].cpu().numpy()\n        y_vals = transformed_features[:, i].detach().cpu().numpy()\n        \n        # Sort for visualization\n        sort_idx = np.argsort(x_vals)\n        x_sorted = x_vals[sort_idx]\n        y_sorted = y_vals[sort_idx]\n        \n        axes[i].scatter(x_vals, y_vals, alpha=0.5, s=10, label='Data points')\n        axes[i].plot(x_sorted, y_sorted, 'r-', alpha=0.8, label='Transformation')\n        axes[i].set_xlabel(f'Original Expression (Gene {i})')\n        axes[i].set_ylabel(f'Transformed Expression')\n        axes[i].set_title(f'Sigmoid Transformation - Gene {i}')\n        axes[i].legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Show learnable parameters for first gene\n    params = sigmoid_module.get_parameters()\n    print(f\"\\\\nParameters for Gene 0:\")\n    print(f\"Slopes: {params['slopes'][0].cpu().numpy()[:5]}\")  # First 5 components\n    print(f\"Biases: {params['biases'][0].cpu().numpy()[:5]}\")\n    print(f\"Weights: {params['weights'][0].cpu().numpy()[:5]}\")\n    \nelse:\n    print(\"Sigmoid feature demonstration requires pytorch and model components\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### 2.2 Linear Interaction Network with ATAC Masking\n\nThe `LinearInteractionNetwork` models gene regulatory interactions with chromatin accessibility constraints:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "if hasattr(tv, 'models'):\n    # Create linear interaction network\n    interaction_net = LinearInteractionNetwork(\n        n_genes=n_genes,\n        use_bias=False,           # No bias terms\n        interaction_strength=1.0  # Scaling factor\n    ).to(device)\n    \n    print(f\"Interaction network parameters: {sum(p.numel() for p in interaction_net.parameters())}\")\n    \n    # Test without ATAC masking\n    interactions_no_mask = interaction_net(transformed_features)\n    \n    # Test with ATAC masking\n    interactions_with_mask = interaction_net(transformed_features, atac_mask=chromatin_tensor)\n    \n    print(f\"\\\\n=== Interaction Network Results ===\")\n    print(f\"Input features shape: {transformed_features.shape}\")\n    print(f\"ATAC mask shape: {chromatin_tensor.shape}\")\n    print(f\"Output without masking: {interactions_no_mask.shape}\")\n    print(f\"Output with masking: {interactions_with_mask.shape}\")\n    \n    # Compare interaction strengths\n    no_mask_norm = torch.norm(interactions_no_mask, dim=1).mean()\n    with_mask_norm = torch.norm(interactions_with_mask, dim=1).mean()\n    \n    print(f\"\\\\nMean interaction strength:\")\n    print(f\"  Without ATAC masking: {no_mask_norm:.4f}\")\n    print(f\"  With ATAC masking: {with_mask_norm:.4f}\")\n    print(f\"  Masking effect: {(with_mask_norm/no_mask_norm):.4f}x\")\n    \n    # Visualize interaction matrix and masking effect\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # Raw interaction matrix (first 20x20 genes)\n    W = interaction_net.W.detach().cpu().numpy()[:20, :20]\n    im1 = axes[0].imshow(W, cmap='RdBu_r', center=0)\n    axes[0].set_title('Raw Interaction Matrix\\\\n(first 20x20 genes)')\n    axes[0].set_xlabel('Gene Index')\n    axes[0].set_ylabel('Gene Index')\n    plt.colorbar(im1, ax=axes[0])\n    \n    # ATAC masking pattern (first 20 genes, first 50 cells)\n    mask_pattern = chromatin_tensor[:50, :20].cpu().numpy()\n    im2 = axes[1].imshow(mask_pattern.T, cmap='Oranges', aspect='auto')\n    axes[1].set_title('ATAC Masking Pattern\\\\n(first 20 genes, 50 cells)')\n    axes[1].set_xlabel('Cell Index')\n    axes[1].set_ylabel('Gene Index')\n    plt.colorbar(im2, ax=axes[1])\n    \n    # Effect of masking on interactions\n    diff = (interactions_with_mask - interactions_no_mask)[:50, :20].detach().cpu().numpy()\n    im3 = axes[2].imshow(diff.T, cmap='RdBu_r', center=0, aspect='auto')\n    axes[2].set_title('Masking Effect on Interactions\\\\n(first 20 genes, 50 cells)')\n    axes[2].set_xlabel('Cell Index')\n    axes[2].set_ylabel('Gene Index')\n    plt.colorbar(im3, ax=axes[2])\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Show statistics\n    print(f\"\\\\n=== Interaction Matrix Statistics ===\")\n    print(f\"Interaction matrix shape: {W.shape}\")\n    print(f\"Non-zero interactions: {(np.abs(W) > 1e-6).sum()}/{W.size}\")\n    print(f\"Mean absolute interaction: {np.abs(W).mean():.6f}\")\n    print(f\"Max interaction strength: {np.abs(W).max():.6f}\")\n    \nelse:\n    print(\"Interaction network demonstration requires model components\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### 2.3 ODE Dynamics and Parameter Prediction\n\nThe `VelocityODE` models RNA dynamics with cell-specific parameters:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if hasattr(tv, 'models'):\n    # Create ODE parameter predictor\n    param_predictor = ODEParameterPredictor(\n        input_dim=n_genes,         # Uses regulatory interactions as input\n        hidden_dim=64,             # Hidden layer size\n        init_beta_range=(0.1, 2.0), # Splicing rate range\n        init_gamma_range=(0.1, 1.0) # Degradation rate range\n    ).to(device)\n    \n    # Predict cell-specific ODE parameters from regulatory interactions\n    ode_params = param_predictor(interactions_with_mask)\n    \n    print(f\"=== ODE Parameter Prediction ===\")\n    print(f\"Input (regulatory interactions): {interactions_with_mask.shape}\")\n    print(f\"Predicted parameters: {ode_params.keys()}\")\n    \n    for param_name, param_tensor in ode_params.items():\n        print(f\"  {param_name}: {param_tensor.shape}, range [{param_tensor.min():.4f}, {param_tensor.max():.4f}]\")\n    \n    # Create ODE dynamics module\n    ode_dynamics = VelocityODE(stage1_config.ode).to(device)\n    \n    # Simulate ODE dynamics with predicted parameters\n    t_span = torch.tensor([0.0, 1.0], device=device)\n    initial_state = torch.stack([unspliced_tensor, spliced_tensor], dim=-1)  # (cells, genes, 2)\n    \n    print(f\"\\\\n=== ODE Integration ===\")\n    print(f\"Time span: {t_span}\")\n    print(f\"Initial state shape: {initial_state.shape}\")\n    print(f\"Initial unspliced range: [{unspliced_tensor.min():.3f}, {unspliced_tensor.max():.3f}]\")\n    print(f\"Initial spliced range: [{spliced_tensor.min():.3f}, {spliced_tensor.max():.3f}]\")\n    \n    # Visualize ODE parameters across cells and genes\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # Beta (splicing rate) distribution\n    beta_vals = ode_params['beta'].detach().cpu().numpy()\n    axes[0].hist(beta_vals.flatten(), bins=30, alpha=0.7, color='blue', edgecolor='black')\n    axes[0].set_xlabel('Splicing Rate (β)')\n    axes[0].set_ylabel('Frequency')\n    axes[0].set_title(f'Splicing Rate Distribution\\\\nMean: {beta_vals.mean():.3f} ± {beta_vals.std():.3f}')\n    axes[0].axvline(beta_vals.mean(), color='red', linestyle='--', label='Mean')\n    axes[0].legend()\n    \n    # Gamma (degradation rate) distribution\n    gamma_vals = ode_params['gamma'].detach().cpu().numpy()\n    axes[1].hist(gamma_vals.flatten(), bins=30, alpha=0.7, color='green', edgecolor='black')\n    axes[1].set_xlabel('Degradation Rate (γ)')\n    axes[1].set_ylabel('Frequency')\n    axes[1].set_title(f'Degradation Rate Distribution\\\\nMean: {gamma_vals.mean():.3f} ± {gamma_vals.std():.3f}')\n    axes[1].axvline(gamma_vals.mean(), color='red', linestyle='--', label='Mean')\n    axes[1].legend()\n    \n    # Time parameter distribution\n    t_vals = ode_params['t'].detach().cpu().numpy()\n    axes[2].hist(t_vals.flatten(), bins=30, alpha=0.7, color='orange', edgecolor='black')\n    axes[2].set_xlabel('Cell Time (t)')\n    axes[2].set_ylabel('Frequency')\n    axes[2].set_title(f'Cell Time Distribution\\\\nMean: {t_vals.mean():.3f} ± {t_vals.std():.3f}')\n    axes[2].axvline(t_vals.mean(), color='red', linestyle='--', label='Mean')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Show correlation between parameters and regulatory interactions\n    interaction_strength = torch.norm(interactions_with_mask, dim=1).detach().cpu().numpy()\n    beta_mean = beta_vals.mean(axis=1)\n    gamma_mean = gamma_vals.mean(axis=1)\n    \n    print(f\"\\\\n=== Parameter Correlations ===\")\n    beta_corr = np.corrcoef(interaction_strength, beta_mean)[0, 1]\n    gamma_corr = np.corrcoef(interaction_strength, gamma_mean)[0, 1]\n    print(f\"Interaction strength vs β: r = {beta_corr:.3f}\")\n    print(f\"Interaction strength vs γ: r = {gamma_corr:.3f}\")\n    \nelse:\n    print(\"ODE dynamics demonstration requires model components\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Full Stage 1 Model Integration\n\nWhile the individual components are demonstrated above, the full Stage 1 model integrates all components. However, the high-level API (`TangeloVelocity`) is currently being developed and requires additional dependencies."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check if Stage 1 model is available\nif hasattr(tv, 'models'):\n    try:\n        from tangelo_velocity.models import Stage1RegulatoryModel, get_velocity_model\n        \n        print(\"=== Stage 1 Model Architecture ===\")\n        print(\"The Stage1RegulatoryModel integrates:\")\n        print(\"1. SigmoidFeatureModule for smooth expression transformation\")\n        print(\"2. LinearInteractionNetwork with ATAC masking\")\n        print(\"3. ODEParameterPredictor for cell-specific dynamics\")\n        print(\"4. VelocityODE for RNA dynamics simulation\")\n        print(\"5. Specialized loss functions (ReconstructionLoss + RegulatoryLoss)\")\n        \n        # Create a Stage 1 model configuration\n        stage1_config.gene_dim = n_genes\n        stage1_config.atac_dim = n_genes  # Using gene-linked chromatin\n        \n        print(f\"\\\\nModel configuration:\")\n        print(f\"  Stage: {stage1_config.development_stage}\")\n        print(f\"  Gene dimension: {stage1_config.gene_dim}\")\n        print(f\"  ATAC dimension: {stage1_config.atac_dim}\")\n        print(f\"  Device: {stage1_config.device}\")\n        \n        # For a complete example, you would instantiate and train the model:\n        print(f\"\\\\n=== Model Usage Example ===\")\n        print(\"# model = get_velocity_model(stage1_config, n_genes, n_genes)\")\n        print(\"# model = model.to(device)\")\n        print(\"# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\")\n        print(\"# loss = model.compute_loss(outputs, targets)\")\n        print(\"# loss.backward()\")\n        print(\"# optimizer.step()\")\n        \n        print(f\"\\\\n✓ Stage 1 components are ready for integration\")\n        \n    except Exception as e:\n        print(f\"Stage 1 model integration note: {e}\")\n        print(\"All individual components demonstrated above are functional\")\n        \nelse:\n    print(\"Stage 1 model demonstration requires dependency installation\")\n    print(\"Individual components shown above demonstrate the core functionality\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. Stage 1 Configuration Customization\n\nYou can customize Stage 1 behavior through configuration:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Create custom Stage 1 configurations for different use cases\n\n# Configuration 1: High regulatory constraints\nhigh_regulatory_config = TangeloConfig(\n    development_stage=1,\n    regulatory=tv.config.RegulatoryConfig(\n        use_atac_masking=True,\n        atac_threshold=0.2,  # Stricter ATAC threshold\n        use_sigmoid_features=True,\n        n_sigmoid_components=20,  # More components for complex transformations\n        interaction_strength=2.0  # Stronger regulatory interactions\n    ),\n    ode=tv.config.ODEConfig(\n        solver=\"dopri5\",\n        rtol=1e-6,  # Higher precision\n        atol=1e-8,\n        init_beta_range=(0.5, 3.0),  # Wider splicing rate range\n        init_gamma_range=(0.1, 1.5)\n    ),\n    training=tv.config.TrainingConfig(\n        n_epochs=150,\n        learning_rate=5e-4,  # Slower learning for stability\n        batch_size=256\n    )\n)\n\n# Configuration 2: Fast training for exploration\nfast_config = TangeloConfig(\n    development_stage=1, \n    regulatory=tv.config.RegulatoryConfig(\n        use_atac_masking=False,  # Disable for speed\n        use_sigmoid_features=True,\n        n_sigmoid_components=5,  # Fewer components\n        interaction_strength=1.0\n    ),\n    training=tv.config.TrainingConfig(\n        n_epochs=50,  # Quick training\n        learning_rate=1e-3,\n        batch_size=512  # Larger batches\n    )\n)\n\n# Configuration 3: High-precision modeling\nprecision_config = TangeloConfig(\n    development_stage=1,\n    regulatory=tv.config.RegulatoryConfig(\n        use_atac_masking=True,\n        atac_threshold=0.05,  # Very fine-grained masking\n        use_sigmoid_features=True, \n        n_sigmoid_components=30,  # Maximum detail\n        interaction_strength=1.5\n    ),\n    ode=tv.config.ODEConfig(\n        solver=\"dopri5\",\n        rtol=1e-7,  # Maximum precision\n        atol=1e-9,\n        max_steps=2000,  # Allow more integration steps\n        n_time_points=100  # Fine temporal resolution\n    ),\n    loss=tv.config.LossConfig(\n        reconstruction_weight=1.0,\n        l2_reg=1e-5  # Light regularization\n    )\n)\n\nprint(\"=== Stage 1 Configuration Examples ===\")\nprint(f\"1. High Regulatory: {high_regulatory_config.regulatory.n_sigmoid_components} sigmoid components, \" +\n      f\"ATAC threshold {high_regulatory_config.regulatory.atac_threshold}\")\nprint(f\"2. Fast Training: {fast_config.training.n_epochs} epochs, \" +\n      f\"batch size {fast_config.training.batch_size}\")\nprint(f\"3. High Precision: {precision_config.ode.rtol} relative tolerance, \" +\n      f\"{precision_config.ode.max_steps} max ODE steps\")\n\n# Save configurations for later use\nhigh_regulatory_config.save_yaml(\"stage1_high_regulatory.yaml\")\nfast_config.save_yaml(\"stage1_fast_training.yaml\")\nprecision_config.save_yaml(\"stage1_high_precision.yaml\")\n\nprint(f\"\\\\n✓ Configurations saved as YAML files\")\nprint(\"You can load them with: TangeloConfig.from_yaml('filename.yaml')\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Summary: Stage 1 Regulatory Model\n\nThis tutorial demonstrated **Tangelo Velocity Stage 1**, focusing on regulatory network modeling for RNA velocity estimation.\n\n### Key Components Implemented:\n\n1. **SigmoidFeatureModule**: Learnable smooth transformations of gene expression with multiple sigmoid components per gene\n2. **LinearInteractionNetwork**: Gene regulatory interactions with ATAC-seq masking for chromatin accessibility constraints  \n3. **VelocityODE**: ODE dynamics modeling with TorchODE integration for RNA splicing/degradation\n4. **ODEParameterPredictor**: Cell-specific prediction of splicing (β) and degradation (γ) rates\n5. **Loss Functions**: ReconstructionLoss and RegulatoryNetworkLoss for training\n\n### Stage 1 Capabilities:\n\n✅ **Regulatory modeling**: Integrates chromatin accessibility data  \n✅ **Cell-specific dynamics**: Predicts individual ODE parameters per cell  \n✅ **Flexible configuration**: Extensive customization options  \n✅ **GPU acceleration**: PyTorch-based implementation with CUDA support  \n\n### Current Implementation Status:\n\n- **Stage 0**: ✅ Complete (preprocessing, graph construction, embeddings)\n- **Stage 1**: ✅ Complete (regulatory modeling as demonstrated)\n- **Stage 2**: 🚧 Planned (graph neural networks for spatial modeling)\n- **Stage 3**: 🚧 Planned (integrated multi-modal architecture)  \n- **Stage 4**: 🚧 Planned (advanced features and hierarchical modeling)\n\n### Next Steps:\n\n1. **Install dependencies** (numpy, torch, scanpy, muon) to run the interactive examples\n2. **Prepare your data** in MuData format with RNA + ATAC modalities\n3. **Configure Stage 1** for your specific use case (regulatory vs speed vs precision)\n4. **Train the model** using the Stage1RegulatoryModel class\n5. **Analyze results** using the component introspection methods\n\nFor questions or issues, see the [Tangelo Velocity GitHub repository](https://github.com/yourusername/tangelo-velocity)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stage comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, stage in enumerate([1, 2, 3]):\n",
    "    velocity = stage_results[stage]['rna'].layers['velocity']\n",
    "    velocity_magnitude = np.linalg.norm(velocity, axis=1)\n",
    "    \n",
    "    # Histogram of velocity magnitudes\n",
    "    axes[i].hist(velocity_magnitude, bins=30, alpha=0.7, density=True)\n",
    "    axes[i].set_xlabel('Velocity Magnitude')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].set_title(f'Stage {stage}\\nVelocity Distribution')\n",
    "    axes[i].axvline(velocity_magnitude.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {velocity_magnitude.mean():.3f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n=== Stage Comparison Summary ===\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Stage': [1, 2, 3],\n",
    "    'Mean_Velocity': [np.linalg.norm(stage_results[s]['rna'].layers['velocity'], axis=1).mean() \n",
    "                     for s in [1, 2, 3]],\n",
    "    'Std_Velocity': [np.linalg.norm(stage_results[s]['rna'].layers['velocity'], axis=1).std() \n",
    "                    for s in [1, 2, 3]],\n",
    "    'Max_Velocity': [np.linalg.norm(stage_results[s]['rna'].layers['velocity'], axis=1).max() \n",
    "                    for s in [1, 2, 3]]\n",
    "})\n",
    "\n",
    "print(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuration Management\n",
    "\n",
    "Save and load configurations for reproducible experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Configuration Management ===\")\n",
    "\n",
    "# Create and save a custom configuration\n",
    "custom_config = tv.TangeloConfig(\n",
    "    development_stage=3,\n",
    "    graph=tv.config.GraphConfig(\n",
    "        n_neighbors_spatial=10,\n",
    "        n_neighbors_expression=20,\n",
    "        use_node2vec=True,\n",
    "        node2vec_dim=64,\n",
    "    ),\n",
    "    encoder=tv.config.EncoderConfig(\n",
    "        latent_dim=64,\n",
    "        hidden_dims=(512, 256, 128),\n",
    "        fusion_method=\"attention\",\n",
    "    ),\n",
    "    training=tv.config.TrainingConfig(\n",
    "        n_epochs=200,\n",
    "        learning_rate=5e-4,\n",
    "        batch_size=1024,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save configuration\n",
    "config_path = Path(\"custom_tangelo_config.yaml\")\n",
    "custom_config.save_yaml(config_path)\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "\n",
    "# Load configuration\n",
    "loaded_config = tv.TangeloConfig.from_yaml(config_path)\n",
    "print(f\"Configuration loaded successfully\")\n",
    "print(f\"  - Stage: {loaded_config.development_stage}\")\n",
    "print(f\"  - Spatial neighbors: {loaded_config.graph.n_neighbors_spatial}\")\n",
    "print(f\"  - Use Node2Vec: {loaded_config.graph.use_node2vec}\")\n",
    "print(f\"  - Latent dim: {loaded_config.encoder.latent_dim}\")\n",
    "print(f\"  - Fusion method: {loaded_config.encoder.fusion_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis and Metrics\n",
    "\n",
    "Evaluate velocity quality and perform trajectory analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Velocity Metrics and Analysis ===\")\n",
    "\n",
    "# Use the best result from stage comparison\n",
    "best_result = stage_results[3]  # Stage 3 result\n",
    "\n",
    "# Initialize velocity metrics\n",
    "try:\n",
    "    metrics = tv.analysis.VelocityMetrics(best_result)\n",
    "    summary = metrics.summary()\n",
    "    \n",
    "    print(\"Velocity Quality Metrics:\")\n",
    "    for metric, value in summary.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Metrics computation not available: {e}\")\n",
    "    \n",
    "    # Compute basic metrics manually\n",
    "    velocity = best_result['rna'].layers['velocity']\n",
    "    velocity_magnitude = np.linalg.norm(velocity, axis=1)\n",
    "    \n",
    "    print(\"Basic Velocity Statistics:\")\n",
    "    print(f\"  Mean magnitude: {velocity_magnitude.mean():.4f}\")\n",
    "    print(f\"  Std magnitude: {velocity_magnitude.std():.4f}\")\n",
    "    print(f\"  Min magnitude: {velocity_magnitude.min():.4f}\")\n",
    "    print(f\"  Max magnitude: {velocity_magnitude.max():.4f}\")\n",
    "    print(f\"  Non-zero velocities: {(velocity_magnitude > 1e-6).sum()}/{len(velocity_magnitude)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving Results\n",
    "\n",
    "Save your velocity estimation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Saving Results ===\")\n",
    "\n",
    "# Save the final result\n",
    "output_path = Path(\"tangelo_velocity_results.h5mu\")\n",
    "best_result.write_h5mu(output_path)\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Save velocity matrix separately\n",
    "velocity_path = Path(\"velocity_matrix.csv\")\n",
    "velocity_df = pd.DataFrame(\n",
    "    best_result['rna'].layers['velocity'],\n",
    "    index=best_result['rna'].obs_names,\n",
    "    columns=best_result['rna'].var_names\n",
    ")\n",
    "velocity_df.to_csv(velocity_path)\n",
    "print(f\"Velocity matrix saved to: {velocity_path}\")\n",
    "\n",
    "# Save cell metadata with ODE parameters\n",
    "metadata_path = Path(\"cell_metadata.csv\")\n",
    "metadata_df = best_result.obs.copy()\n",
    "metadata_df.to_csv(metadata_path)\n",
    "print(f\"Cell metadata saved to: {metadata_path}\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated:\n",
    "\n",
    "1. **Data preparation** for Tangelo Velocity (MuData with spatial, RNA, and ATAC modalities)\n",
    "2. **Basic velocity estimation** with one-line interface\n",
    "3. **Advanced API usage** with custom configurations\n",
    "4. **Model component extraction** (latent representations, ODE parameters, interaction networks)\n",
    "5. **Downstream analysis** (velocity graphs, embeddings, visualization)\n",
    "6. **Stage comparison** across different development stages\n",
    "7. **Configuration management** for reproducible experiments\n",
    "8. **Quality metrics** and analysis tools\n",
    "9. **Result saving** and export\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Use your own data**: Replace the synthetic data with your multi-modal dataset\n",
    "- **Experiment with stages**: Try different development stages (1-4) based on your needs\n",
    "- **Tune parameters**: Adjust graph construction, encoder architecture, and training parameters\n",
    "- **Advanced analysis**: Explore perturbation analysis and trajectory modeling\n",
    "- **Visualization**: Create publication-ready plots with the plotting module\n",
    "\n",
    "For more information, see the [Tangelo Velocity documentation](https://github.com/yourusername/tangelo-velocity)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}