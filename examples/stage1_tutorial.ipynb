{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tangelo Velocity: Stage 1 Tutorial\n",
    "\n",
    "This notebook demonstrates **Tangelo Velocity Stage 1** - a regulatory network model for RNA velocity estimation that integrates chromatin accessibility (ATAC-seq) data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Stage 1** implements:\n",
    "- **Sigmoid Feature Transformation**: Learnable smooth feature mapping\n",
    "- **Linear Interaction Networks**: Gene regulatory interactions with ATAC masking\n",
    "- **ODE Dynamics**: Cell-specific splicing and degradation modeling\n",
    "- **Regulatory Loss Functions**: Reconstruction and constraint losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports (always available)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tangelo Velocity\n",
    "import tangelo_velocity as tv\n",
    "\n",
    "print(f\"Tangelo Velocity version: {tv.__version__}\")\n",
    "print(f\"Available modules: {[x for x in tv.__all__ if not x.startswith('_')]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what model components are available\n",
    "print(\"=== Model Component Availability ===\")\n",
    "\n",
    "if hasattr(tv, 'models'):\n",
    "    print(\"âœ“ Models module is available\")\n",
    "    \n",
    "    # List available components\n",
    "    if hasattr(tv.models, 'list_available_components'):\n",
    "        available_components = tv.models.list_available_components()\n",
    "        print(f\"Available components ({len(available_components)}):\")\n",
    "        for comp in available_components:\n",
    "            print(f\"  - {comp}\")\n",
    "    \n",
    "    # Check direct package-level access\n",
    "    stage1_components = [\n",
    "        'SigmoidFeatureModule', 'LinearInteractionNetwork', \n",
    "        'VelocityODE', 'ODEParameterPredictor',\n",
    "        'ReconstructionLoss', 'Stage1RegulatoryModel'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nStage 1 component availability:\")\n",
    "    for comp in stage1_components:\n",
    "        available = hasattr(tv, comp)\n",
    "        status = \"âœ“\" if available else \"âŒ\"\n",
    "        print(f\"  {status} {comp}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Models module not available\")\n",
    "    print(\"This likely means PyTorch dependencies are not installed\")\n",
    "    print(\"\\nYou can still explore:\")\n",
    "    print(\"  - Configuration system\")\n",
    "    print(\"  - Synthetic data generation patterns\")\n",
    "    print(\"  - Stage planning and concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Configuration\n",
    "\n",
    "Even without PyTorch, you can explore the configuration system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 configuration (always available)\n",
    "from tangelo_velocity.config import get_stage_config\n",
    "\n",
    "stage1_config = get_stage_config(stage=1)\n",
    "\n",
    "print(\"=== Stage 1 Configuration ===\")\n",
    "print(f\"Development Stage: {stage1_config.development_stage}\")\n",
    "print(f\"Gene/ATAC dimensions: {stage1_config.gene_dim}/{stage1_config.atac_dim} (inferred from data)\")\n",
    "\n",
    "print(\"\\n=== Regulatory Network Configuration ===\")\n",
    "print(f\"Use ATAC masking: {stage1_config.regulatory.use_atac_masking}\")\n",
    "print(f\"ATAC threshold: {stage1_config.regulatory.atac_threshold}\")\n",
    "print(f\"Sigmoid components: {stage1_config.regulatory.n_sigmoid_components}\")\n",
    "print(f\"Interaction strength: {stage1_config.regulatory.interaction_strength}\")\n",
    "\n",
    "print(\"\\n=== ODE Configuration ===\")\n",
    "print(f\"Solver: {stage1_config.ode.solver}\")\n",
    "print(f\"Time span: {stage1_config.ode.t_span}\")\n",
    "print(f\"Beta range: {stage1_config.ode.init_beta_range}\")\n",
    "print(f\"Gamma range: {stage1_config.ode.init_gamma_range}\")\n",
    "\n",
    "print(\"\\n=== Training Configuration ===\")\n",
    "print(f\"Epochs: {stage1_config.training.n_epochs}\")\n",
    "print(f\"Learning rate: {stage1_config.training.learning_rate}\")\n",
    "print(f\"Batch size: {stage1_config.training.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data for Stage 1\n",
    "\n",
    "Create realistic multi-modal data with regulatory relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage1_synthetic_data(n_cells=300, n_genes=100, n_peaks=150, seed=42):\n",
    "    \"\"\"Create synthetic data with regulatory structure for Stage 1 demo.\"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    print(f\"Creating synthetic Stage 1 data: {n_cells} cells, {n_genes} genes, {n_peaks} peaks\")\n",
    "    \n",
    "    # Create cell types with different expression programs\n",
    "    n_types = 3\n",
    "    cell_types = np.random.choice(n_types, n_cells)\n",
    "    \n",
    "    # Base expression with cell type effects\n",
    "    base_expr = np.random.gamma(2, 1, (n_cells, n_genes))\n",
    "    for ct in range(n_types):\n",
    "        mask = cell_types == ct\n",
    "        # Each cell type upregulates different gene sets\n",
    "        gene_start = ct * (n_genes // n_types)\n",
    "        gene_end = (ct + 1) * (n_genes // n_types)\n",
    "        base_expr[mask, gene_start:gene_end] *= 2.5\n",
    "    \n",
    "    # Simulate splicing dynamics\n",
    "    splicing_rate = np.random.beta(3, 2, n_genes)  # Gene-specific splicing efficiency\n",
    "    degradation_rate = np.random.beta(2, 3, n_genes)  # Gene-specific degradation\n",
    "    \n",
    "    # Create spliced/unspliced based on kinetics\n",
    "    unspliced = base_expr * (1 - splicing_rate) + np.random.gamma(0.5, 1, (n_cells, n_genes))\n",
    "    spliced = base_expr * splicing_rate * (1 - degradation_rate) + np.random.gamma(0.5, 1, (n_cells, n_genes))\n",
    "    \n",
    "    # Create regulatory network: peaks -> genes\n",
    "    peak_gene_links = np.random.binomial(1, 0.25, (n_peaks, n_genes))\n",
    "    \n",
    "    # ATAC data correlates with linked gene expression\n",
    "    atac_data = np.zeros((n_cells, n_peaks))\n",
    "    for peak in range(n_peaks):\n",
    "        linked_genes = peak_gene_links[peak, :] > 0\n",
    "        if linked_genes.sum() > 0:\n",
    "            # Accessibility correlates with gene activity\n",
    "            atac_data[:, peak] = spliced[:, linked_genes].mean(axis=1) * 0.3\n",
    "        atac_data[:, peak] += np.random.gamma(0.3, 1, n_cells)  # Background + noise\n",
    "    \n",
    "    # Binary chromatin accessibility for regulatory masking\n",
    "    accessibility_threshold = np.percentile(atac_data, 75, axis=0)\n",
    "    open_chromatin = (atac_data > accessibility_threshold).astype(float)\n",
    "    \n",
    "    # Gene-level chromatin signal (for regulatory networks)\n",
    "    gene_chromatin = np.zeros((n_cells, n_genes))\n",
    "    for gene in range(n_genes):\n",
    "        linked_peaks = peak_gene_links[:, gene] > 0\n",
    "        if linked_peaks.sum() > 0:\n",
    "            gene_chromatin[:, gene] = open_chromatin[:, linked_peaks].mean(axis=1)\n",
    "        else:\n",
    "            gene_chromatin[:, gene] = np.random.binomial(1, 0.1, n_cells)  # Background\n",
    "    \n",
    "    # Moments for scVelo compatibility\n",
    "    M_s = spliced + np.random.normal(0, 0.05 * spliced)\n",
    "    M_u = unspliced + np.random.normal(0, 0.05 * unspliced)\n",
    "    \n",
    "    print(f\"âœ“ Created data with {peak_gene_links.sum()} peak-gene regulatory links\")\n",
    "    print(f\"âœ“ {(gene_chromatin > 0.3).sum()} gene-cell accessibility pairs\")\n",
    "    \n",
    "    return {\n",
    "        'n_cells': n_cells, 'n_genes': n_genes, 'n_peaks': n_peaks,\n",
    "        'spliced': spliced.astype(np.float32),\n",
    "        'unspliced': unspliced.astype(np.float32),\n",
    "        'M_s': M_s.astype(np.float32),\n",
    "        'M_u': M_u.astype(np.float32),\n",
    "        'atac_data': atac_data.astype(np.float32),\n",
    "        'gene_chromatin': gene_chromatin.astype(np.float32),\n",
    "        'cell_types': cell_types,\n",
    "        'peak_gene_links': peak_gene_links,\n",
    "        'true_splicing_rate': splicing_rate,\n",
    "        'true_degradation_rate': degradation_rate\n",
    "    }\n",
    "\n",
    "# Create demo data\n",
    "data = create_stage1_synthetic_data(n_cells=300, n_genes=100, n_peaks=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the synthetic data structure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Spliced vs Unspliced by cell type\n",
    "for ct in range(3):\n",
    "    mask = data['cell_types'] == ct\n",
    "    axes[0, 0].scatter(\n",
    "        np.log1p(data['spliced'][mask].mean(axis=1)),\n",
    "        np.log1p(data['unspliced'][mask].mean(axis=1)),\n",
    "        label=f'Type {ct}', alpha=0.7, s=15\n",
    "    )\n",
    "axes[0, 0].set_xlabel('Log(Spliced + 1)')\n",
    "axes[0, 0].set_ylabel('Log(Unspliced + 1)')\n",
    "axes[0, 0].set_title('RNA Expression by Cell Type')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Chromatin accessibility distribution\n",
    "accessibility_mean = data['gene_chromatin'].mean(axis=0)\n",
    "axes[0, 1].hist(accessibility_mean, bins=20, alpha=0.7, color='orange')\n",
    "axes[0, 1].set_xlabel('Mean Gene Accessibility')\n",
    "axes[0, 1].set_ylabel('Number of Genes')\n",
    "axes[0, 1].set_title('Chromatin Accessibility Distribution')\n",
    "\n",
    "# 3. Expression vs Accessibility correlation\n",
    "expr_mean = data['spliced'].mean(axis=0)\n",
    "corr = np.corrcoef(expr_mean, accessibility_mean)[0, 1]\n",
    "axes[0, 2].scatter(expr_mean, accessibility_mean, alpha=0.6, s=15)\n",
    "axes[0, 2].set_xlabel('Mean Spliced Expression')\n",
    "axes[0, 2].set_ylabel('Mean Accessibility')\n",
    "axes[0, 2].set_title(f'Expression vs Accessibility\\n(r = {corr:.3f})')\n",
    "\n",
    "# 4. Splicing efficiency distribution\n",
    "observed_efficiency = data['spliced'] / (data['spliced'] + data['unspliced'] + 1e-6)\n",
    "axes[1, 0].hist(observed_efficiency.mean(axis=0), bins=20, alpha=0.7, color='green')\n",
    "axes[1, 0].set_xlabel('Observed Splicing Efficiency')\n",
    "axes[1, 0].set_ylabel('Number of Genes')\n",
    "axes[1, 0].set_title('Splicing Efficiency')\n",
    "\n",
    "# 5. Peak-gene regulatory network heatmap\n",
    "network_subset = data['peak_gene_links'][:30, :30]  # Show subset\n",
    "im = axes[1, 1].imshow(network_subset, cmap='Blues', aspect='auto')\n",
    "axes[1, 1].set_xlabel('Genes (first 30)')\n",
    "axes[1, 1].set_ylabel('Peaks (first 30)')\n",
    "axes[1, 1].set_title('Peak-Gene Regulatory Network')\n",
    "plt.colorbar(im, ax=axes[1, 1], shrink=0.8)\n",
    "\n",
    "# 6. Cell type composition\n",
    "type_counts = np.bincount(data['cell_types'])\n",
    "axes[1, 2].pie(type_counts, labels=[f'Type {i}' for i in range(len(type_counts))],\n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 2].set_title('Cell Type Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Data Summary ===\")\n",
    "print(f\"Cells: {data['n_cells']}, Genes: {data['n_genes']}, Peaks: {data['n_peaks']}\")\n",
    "print(f\"Regulatory connections: {data['peak_gene_links'].sum()}\")\n",
    "print(f\"Mean expression: {data['spliced'].mean():.2f}\")\n",
    "print(f\"Mean accessibility: {data['gene_chromatin'].mean():.3f}\")\n",
    "print(f\"Expression-accessibility correlation: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Component Usage (with PyTorch)\n",
    "\n",
    "If you have PyTorch installed, you can test the individual Stage 1 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Stage 1 components if available\n",
    "if hasattr(tv, 'models') and hasattr(tv, 'SigmoidFeatureModule'):\n",
    "    import torch\n",
    "    \n",
    "    print(\"=== Testing Stage 1 Components with PyTorch ===\")\n",
    "    \n",
    "    # Convert data to tensors\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    spliced_tensor = torch.tensor(data['spliced'], dtype=torch.float32, device=device)\n",
    "    chromatin_tensor = torch.tensor(data['gene_chromatin'], dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Data shapes - Spliced: {spliced_tensor.shape}, Chromatin: {chromatin_tensor.shape}\")\n",
    "    \n",
    "    # 1. Test SigmoidFeatureModule\n",
    "    sigmoid_module = tv.SigmoidFeatureModule(\n",
    "        n_genes=data['n_genes'],\n",
    "        n_components=5,  # Reduced for demo\n",
    "        init_a=1.0,\n",
    "        init_b=0.0\n",
    "    ).to(device)\n",
    "    \n",
    "    transformed_features = sigmoid_module(spliced_tensor)\n",
    "    print(f\"\\nâœ“ SigmoidFeatureModule: {spliced_tensor.shape} â†’ {transformed_features.shape}\")\n",
    "    \n",
    "    # 2. Test LinearInteractionNetwork\n",
    "    interaction_net = tv.LinearInteractionNetwork(\n",
    "        n_genes=data['n_genes'],\n",
    "        use_bias=False,\n",
    "        interaction_strength=1.0\n",
    "    ).to(device)\n",
    "    \n",
    "    interactions_no_mask = interaction_net(transformed_features)\n",
    "    interactions_with_mask = interaction_net(transformed_features, atac_mask=chromatin_tensor)\n",
    "    \n",
    "    print(f\"âœ“ LinearInteractionNetwork: {transformed_features.shape} â†’ {interactions_with_mask.shape}\")\n",
    "    \n",
    "    # Compare masking effect\n",
    "    no_mask_norm = torch.norm(interactions_no_mask, dim=1).mean().item()\n",
    "    with_mask_norm = torch.norm(interactions_with_mask, dim=1).mean().item()\n",
    "    print(f\"  Interaction strength - No mask: {no_mask_norm:.4f}, With ATAC mask: {with_mask_norm:.4f}\")\n",
    "    print(f\"  ATAC masking effect: {with_mask_norm/no_mask_norm:.3f}x\")\n",
    "    \n",
    "    # 3. Test ODEParameterPredictor  \n",
    "    param_predictor = tv.ODEParameterPredictor(\n",
    "        input_dim=data['n_genes'],\n",
    "        hidden_dim=32,  # Reduced for demo\n",
    "        init_beta_range=(0.1, 2.0),\n",
    "        init_gamma_range=(0.1, 1.0)\n",
    "    ).to(device)\n",
    "    \n",
    "    ode_params = param_predictor(interactions_with_mask)\n",
    "    print(f\"\\nâœ“ ODEParameterPredictor: {interactions_with_mask.shape} â†’ {list(ode_params.keys())}\")\n",
    "    \n",
    "    for param_name, param_tensor in ode_params.items():\n",
    "        print(f\"  {param_name}: shape {param_tensor.shape}, range [{param_tensor.min():.3f}, {param_tensor.max():.3f}]\")\n",
    "    \n",
    "    # 4. Test Loss Functions\n",
    "    recon_loss = tv.ReconstructionLoss()\n",
    "    reg_loss = tv.RegulatoryNetworkLoss()\n",
    "    \n",
    "    # Dummy targets for loss computation\n",
    "    targets = {\n",
    "        'spliced': spliced_tensor,\n",
    "        'unspliced': torch.tensor(data['unspliced'], dtype=torch.float32, device=device)\n",
    "    }\n",
    "    \n",
    "    outputs = {\n",
    "        'pred_spliced': spliced_tensor + torch.randn_like(spliced_tensor) * 0.1,\n",
    "        'pred_unspliced': targets['unspliced'] + torch.randn_like(targets['unspliced']) * 0.1\n",
    "    }\n",
    "    \n",
    "    recon_loss_val = recon_loss(outputs, targets)\n",
    "    reg_loss_val = reg_loss(interaction_net.W, chromatin_tensor)\n",
    "    \n",
    "    print(f\"\\nâœ“ Loss Functions:\")\n",
    "    print(f\"  Reconstruction loss: {recon_loss_val.item():.4f}\")\n",
    "    print(f\"  Regulatory loss: {reg_loss_val.item():.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ All Stage 1 components working correctly!\")\n",
    "    \n",
    "else:\n",
    "    print(\"=== Stage 1 Components Not Available ===\")\n",
    "    print(\"To test components, install required dependencies:\")\n",
    "    print(\"  pip install torch torchode\")\n",
    "    print(\"\\nOr use Google Colab which has PyTorch pre-installed\")\n",
    "    print(\"\\nEven without PyTorch, you can:\")\n",
    "    print(\"  âœ“ Explore configuration options\")\n",
    "    print(\"  âœ“ Understand data structures\")\n",
    "    print(\"  âœ“ Plan Stage 1 experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Customization\n",
    "\n",
    "Create custom configurations for different research scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configurations for different use cases\n",
    "from tangelo_velocity.config import TangeloConfig\n",
    "\n",
    "# 1. High regulatory constraint configuration\n",
    "high_reg_config = TangeloConfig(\n",
    "    development_stage=1,\n",
    "    regulatory=tv.config.RegulatoryConfig(\n",
    "        use_atac_masking=True,\n",
    "        atac_threshold=0.15,  # Stricter threshold\n",
    "        n_sigmoid_components=15,  # More components\n",
    "        interaction_strength=1.5\n",
    "    ),\n",
    "    ode=tv.config.ODEConfig(\n",
    "        solver=\"dopri5\",\n",
    "        rtol=1e-6,  # Higher precision\n",
    "        init_beta_range=(0.2, 2.5),\n",
    "        init_gamma_range=(0.1, 1.2)\n",
    "    ),\n",
    "    training=tv.config.TrainingConfig(\n",
    "        n_epochs=150,\n",
    "        learning_rate=3e-4,  # Conservative learning rate\n",
    "        batch_size=256\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Fast exploration configuration\n",
    "fast_config = TangeloConfig(\n",
    "    development_stage=1,\n",
    "    regulatory=tv.config.RegulatoryConfig(\n",
    "        use_atac_masking=False,  # Skip for speed\n",
    "        n_sigmoid_components=5,   # Minimal components\n",
    "        interaction_strength=1.0\n",
    "    ),\n",
    "    training=tv.config.TrainingConfig(\n",
    "        n_epochs=50,   # Quick training\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=512  # Large batches\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Precision configuration for publication\n",
    "precision_config = TangeloConfig(\n",
    "    development_stage=1,\n",
    "    regulatory=tv.config.RegulatoryConfig(\n",
    "        use_atac_masking=True,\n",
    "        atac_threshold=0.05,  # Very sensitive\n",
    "        n_sigmoid_components=25,  # Maximum detail\n",
    "        interaction_strength=1.2\n",
    "    ),\n",
    "    ode=tv.config.ODEConfig(\n",
    "        solver=\"dopri5\",\n",
    "        rtol=1e-7,  # Maximum precision\n",
    "        atol=1e-9,\n",
    "        max_steps=1500,\n",
    "        n_time_points=75\n",
    "    ),\n",
    "    training=tv.config.TrainingConfig(\n",
    "        n_epochs=250,\n",
    "        learning_rate=1e-4,  # Very conservative\n",
    "        batch_size=128   # Smaller batches for stability\n",
    "    )\n",
    ")\n",
    "\n",
    "configs = {\n",
    "    \"High Regulatory\": high_reg_config,\n",
    "    \"Fast Exploration\": fast_config, \n",
    "    \"Publication Precision\": precision_config\n",
    "}\n",
    "\n",
    "print(\"=== Stage 1 Configuration Comparison ===\")\n",
    "print(f\"{'Configuration':<20} {'ATAC Mask':<10} {'Sigmoid':<8} {'Epochs':<7} {'LR':<8} {'Batch':<6}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"{name:<20} {str(config.regulatory.use_atac_masking):<10} \"\n",
    "          f\"{config.regulatory.n_sigmoid_components:<8} \"\n",
    "          f\"{config.training.n_epochs:<7} \"\n",
    "          f\"{config.training.learning_rate:<8.0e} \"\n",
    "          f\"{config.training.batch_size:<6}\")\n",
    "\n",
    "# Save configurations\n",
    "for name, config in configs.items():\n",
    "    filename = f\"stage1_{name.lower().replace(' ', '_')}_config.yaml\"\n",
    "    config.save_yaml(filename)\n",
    "    print(f\"âœ“ Saved {filename}\")\n",
    "\n",
    "print(f\"\\nLoad configurations with: TangeloConfig.from_yaml('filename.yaml')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated **Tangelo Velocity Stage 1**:\n",
    "\n",
    "### âœ… What Works Now (Stage 1):\n",
    "- **Configuration System**: Comprehensive, customizable settings\n",
    "- **Synthetic Data**: Realistic multi-modal data with regulatory structure  \n",
    "- **Component Architecture**: Modular design ready for integration\n",
    "- **PyTorch Components** (if dependencies installed):\n",
    "  - SigmoidFeatureModule for smooth transformations\n",
    "  - LinearInteractionNetwork with ATAC masking\n",
    "  - ODEParameterPredictor for cell-specific dynamics\n",
    "  - Loss functions for training\n",
    "\n",
    "### ðŸš§ Development Roadmap:\n",
    "- **Stage 0**: âœ… Complete (preprocessing, graphs)\n",
    "- **Stage 1**: âœ… Complete (regulatory modeling)\n",
    "- **Stage 2**: ðŸ”„ Planned (graph neural networks)\n",
    "- **Stage 3**: ðŸ”„ Planned (integrated architecture)\n",
    "- **Stage 4**: ðŸ”„ Planned (advanced features)\n",
    "\n",
    "### ðŸ”§ Next Steps:\n",
    "1. **Install dependencies**: `pip install torch torchode scanpy muon`\n",
    "2. **Prepare your data**: MuData format with RNA + ATAC modalities\n",
    "3. **Choose configuration**: Select appropriate Stage 1 settings\n",
    "4. **Train model**: Use Stage1RegulatoryModel class\n",
    "5. **Analyze results**: Extract regulatory networks and dynamics\n",
    "\n",
    "### ðŸ“š Resources:\n",
    "- [Configuration examples](https://github.com/yourusername/tangelo-velocity/examples/)\n",
    "- [API documentation](https://tangelo-velocity.readthedocs.io/)\n",
    "- [Issues & support](https://github.com/yourusername/tangelo-velocity/issues)\n",
    "\n",
    "**Stage 1 provides a solid foundation for regulatory network-based velocity estimation!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}