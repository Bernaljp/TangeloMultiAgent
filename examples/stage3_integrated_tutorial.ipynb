{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Integrated Multi-Modal Velocity Estimation\n",
    "\n",
    "This notebook demonstrates **Tangelo Velocity Stage 3** - an integrated model that combines regulatory networks and graph neural networks for comprehensive RNA velocity estimation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Stage 3** integrates:\n",
    "- **Regulatory Network**: Sigmoid features with ATAC masking (Î± = W(sigmoid(s)))\n",
    "- **Dual GraphSAGE Encoders**: Spatial and expression-based graph learning\n",
    "- **Multi-Modal Fusion**: Combines regulatory and graph-based predictions\n",
    "- **ATAC-Graph Integration**: Chromatin accessibility guides both regulatory and spatial modeling\n",
    "- **Comprehensive Visualization**: Unified analysis of integrated features\n",
    "\n",
    "## Key Mathematical Formulation\n",
    "\n",
    "The integrated model combines:\n",
    "1. **Regulatory transcription**: Î± = W(sigmoid(s)) with ATAC masking\n",
    "2. **Graph embeddings**: Spatial z_spatial and expression z_expr representations\n",
    "3. **Fused predictions**: Î±_integrated = f(Î±_regulatory, z_spatial, z_expr)\n",
    "4. **ODE dynamics**: ds/dt = Î±_integrated - Î²s, du/dt = Î²s - Î³u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "# Check for required dependencies\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    HAS_TORCH = True\n",
    "    print(f\"âœ“ PyTorch {torch.__version__} available\")\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\"âŒ PyTorch not available. Install with: pip install torch\")\n",
    "\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.nn import SAGEConv\n",
    "    HAS_TORCH_GEOMETRIC = True\n",
    "    print(f\"âœ“ PyTorch Geometric {torch_geometric.__version__} available\")\n",
    "except ImportError:\n",
    "    HAS_TORCH_GEOMETRIC = False\n",
    "    print(\"âŒ PyTorch Geometric not available. Install with: pip install torch_geometric\")\n",
    "\n",
    "try:\n",
    "    import muon as mu\n",
    "    import scanpy as sc\n",
    "    HAS_SCANPY = True\n",
    "    print(f\"âœ“ Scanpy and Muon available\")\n",
    "except ImportError:\n",
    "    HAS_SCANPY = False\n",
    "    print(\"âŒ Scanpy/Muon not available. Install with: pip install scanpy muon\")\n",
    "\n",
    "# Tangelo Velocity (should always be available)\n",
    "import tangelo_velocity as tv\n",
    "print(f\"âœ“ Tangelo Velocity {tv.__version__} available\")\n",
    "\n",
    "# Check if Stage 3 is implemented\n",
    "try:\n",
    "    from tangelo_velocity.models.stage3 import Stage3IntegratedModel\n",
    "    HAS_STAGE3 = True\n",
    "    print(\"âœ“ Stage 3 implementation available\")\n",
    "except ImportError:\n",
    "    HAS_STAGE3 = False\n",
    "    print(\"âš ï¸  Stage 3 implementation not yet available - using mock implementation\")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Dependencies\n",
    "\n",
    "Let's handle missing dependencies gracefully and provide clear guidance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dependencies():\n",
    "    \"\"\"Check and report on required dependencies for Stage 3.\"\"\"\n",
    "    dependencies = {\n",
    "        'PyTorch': HAS_TORCH,\n",
    "        'PyTorch Geometric': HAS_TORCH_GEOMETRIC,\n",
    "        'Scanpy/Muon': HAS_SCANPY,\n",
    "        'Stage 3 Model': HAS_STAGE3\n",
    "    }\n",
    "    \n",
    "    print(\"=== Dependency Check ===\")\n",
    "    missing = []\n",
    "    for dep, available in dependencies.items():\n",
    "        status = \"âœ“\" if available else \"âŒ\"\n",
    "        print(f\"{status} {dep}\")\n",
    "        if not available:\n",
    "            missing.append(dep)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"\\nâš ï¸  Missing dependencies: {', '.join(missing)}\")\n",
    "        print(\"\\nInstallation commands:\")\n",
    "        if 'PyTorch' in missing:\n",
    "            print(\"  pip install torch\")\n",
    "        if 'PyTorch Geometric' in missing:\n",
    "            print(\"  pip install torch_geometric\")\n",
    "        if 'Scanpy/Muon' in missing:\n",
    "            print(\"  pip install scanpy muon\")\n",
    "        if 'Stage 3 Model' in missing:\n",
    "            print(\"  Stage 3 is under development - using mock implementation\")\n",
    "        \n",
    "        print(\"\\nðŸ“– This tutorial will show concept and architecture even without all dependencies.\")\n",
    "    else:\n",
    "        print(\"\\nðŸŽ‰ All dependencies available! Full Stage 3 functionality ready.\")\n",
    "    \n",
    "    return all(dependencies.values())\n",
    "\n",
    "all_deps_available = check_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 Configuration\n",
    "\n",
    "Configure the integrated model with both regulatory and graph parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 configuration\n",
    "from tangelo_velocity.config import TangeloConfig\n",
    "\n",
    "# Create comprehensive Stage 3 configuration\n",
    "config = TangeloConfig(\n",
    "    development_stage=3,\n",
    "    \n",
    "    # Regulatory network settings (Stage 1 components)\n",
    "    regulatory=tv.config.RegulatoryConfig(\n",
    "        use_atac_masking=True,\n",
    "        atac_threshold=0.1,\n",
    "        n_sigmoid_components=12,\n",
    "        interaction_strength=1.2,\n",
    "        soft_constraint=True,\n",
    "        lambda_l1=0.01,\n",
    "        lambda_l2=0.001\n",
    "    ),\n",
    "    \n",
    "    # Graph encoder settings (Stage 2 components)\n",
    "    graph=tv.config.GraphConfig(\n",
    "        # Spatial graph parameters\n",
    "        spatial_k=10,\n",
    "        spatial_metric='euclidean',\n",
    "        spatial_latent_dim=32,\n",
    "        \n",
    "        # Expression graph parameters  \n",
    "        expression_k=15,\n",
    "        expression_metric='cosine',\n",
    "        expression_latent_dim=32,\n",
    "        \n",
    "        # GraphSAGE architecture\n",
    "        hidden_dims=(128, 64, 32),\n",
    "        aggregator='mean',\n",
    "        dropout=0.1,\n",
    "        batch_norm=True,\n",
    "        \n",
    "        # Fusion strategy\n",
    "        fusion_method='attention',  # 'sum', 'concat', or 'attention'\n",
    "        fusion_hidden_dim=64\n",
    "    ),\n",
    "    \n",
    "    # ODE solver settings\n",
    "    ode=tv.config.ODEConfig(\n",
    "        solver=\"dopri5\",\n",
    "        rtol=1e-5,\n",
    "        atol=1e-7,\n",
    "        t_span=(0.0, 1.0),\n",
    "        n_time_points=50,\n",
    "        init_beta_range=(0.1, 2.0),\n",
    "        init_gamma_range=(0.1, 1.0)\n",
    "    ),\n",
    "    \n",
    "    # Training configuration\n",
    "    training=tv.config.TrainingConfig(\n",
    "        n_epochs=200,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=256,\n",
    "        weight_decay=1e-4,\n",
    "        scheduler='cosine',\n",
    "        \n",
    "        # Stage 3 specific loss weights\n",
    "        regulatory_weight=0.4,\n",
    "        graph_weight=0.4, \n",
    "        fusion_weight=0.2,\n",
    "        kl_weight=0.01\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=== Stage 3 Configuration ===\")\n",
    "print(f\"Development Stage: {config.development_stage}\")\n",
    "print(f\"\\n=== Regulatory Components (Stage 1) ===\")\n",
    "print(f\"ATAC masking: {config.regulatory.use_atac_masking}\")\n",
    "print(f\"Sigmoid components: {config.regulatory.n_sigmoid_components}\")\n",
    "print(f\"Interaction strength: {config.regulatory.interaction_strength}\")\n",
    "print(f\"L1/L2 regularization: {config.regulatory.lambda_l1}/{config.regulatory.lambda_l2}\")\n",
    "\n",
    "print(f\"\\n=== Graph Components (Stage 2) ===\")\n",
    "print(f\"Spatial k-NN: {config.graph.spatial_k}\")\n",
    "print(f\"Expression k-NN: {config.graph.expression_k}\")\n",
    "print(f\"Latent dimensions: {config.graph.spatial_latent_dim}/{config.graph.expression_latent_dim}\")\n",
    "print(f\"GraphSAGE layers: {config.graph.hidden_dims}\")\n",
    "print(f\"Fusion method: {config.graph.fusion_method}\")\n",
    "\n",
    "print(f\"\\n=== Integration Settings ===\")\n",
    "print(f\"Loss weights - Regulatory: {config.training.regulatory_weight}\")\n",
    "print(f\"             Graph: {config.training.graph_weight}\")\n",
    "print(f\"             Fusion: {config.training.fusion_weight}\")\n",
    "print(f\"             KL: {config.training.kl_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Validation\n",
    "\n",
    "Load your MuData format data or create synthetic data for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage3_synthetic_data(n_cells=2399, n_genes=500, n_peaks=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Create synthetic multi-modal data matching the expected format:\n",
    "    - 2399 cells (as specified)\n",
    "    - RNA modality with spliced/unspliced layers\n",
    "    - ATAC modality with peak accessibility\n",
    "    - Spatial coordinates (x_pixel, y_pixel)\n",
    "    - Realistic regulatory relationships\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    print(f\"Creating Stage 3 synthetic data: {n_cells} cells, {n_genes} genes, {n_peaks} peaks\")\n",
    "    \n",
    "    # 1. Spatial coordinates (tissue-like 2D structure)\n",
    "    tissue_width, tissue_height = 100, 100\n",
    "    x_coords = np.random.uniform(0, tissue_width, n_cells)\n",
    "    y_coords = np.random.uniform(0, tissue_height, n_cells)\n",
    "    \n",
    "    # Create spatial regions with different characteristics\n",
    "    n_regions = 4\n",
    "    region_centers = [(25, 25), (75, 25), (25, 75), (75, 75)]\n",
    "    \n",
    "    # Assign cells to regions based on proximity\n",
    "    cell_regions = np.zeros(n_cells, dtype=int)\n",
    "    for i in range(n_cells):\n",
    "        distances = [np.sqrt((x_coords[i] - cx)**2 + (y_coords[i] - cy)**2) \n",
    "                    for cx, cy in region_centers]\n",
    "        cell_regions[i] = np.argmin(distances)\n",
    "    \n",
    "    # 2. Gene expression with spatial and regulatory structure\n",
    "    base_expression = np.random.gamma(2, 1, (n_cells, n_genes))\n",
    "    \n",
    "    # Add spatial gradients\n",
    "    for region in range(n_regions):\n",
    "        region_mask = cell_regions == region\n",
    "        # Each region has upregulated gene sets\n",
    "        gene_start = region * (n_genes // n_regions)\n",
    "        gene_end = (region + 1) * (n_genes // n_regions)\n",
    "        base_expression[region_mask, gene_start:gene_end] *= 2.0\n",
    "    \n",
    "    # Add smooth spatial gradients\n",
    "    for gene in range(0, n_genes, 10):  # Every 10th gene\n",
    "        spatial_effect = (x_coords / tissue_width) * (1 + 0.5 * np.sin(2 * np.pi * y_coords / tissue_height))\n",
    "        base_expression[:, gene] *= (1 + spatial_effect)\n",
    "    \n",
    "    # 3. RNA velocity dynamics\n",
    "    # Gene-specific kinetic parameters\n",
    "    alpha_true = np.random.gamma(1.5, 1, n_genes)  # Transcription rates\n",
    "    beta_true = np.random.gamma(2, 0.5, n_genes)   # Splicing rates\n",
    "    gamma_true = np.random.gamma(1.5, 0.3, n_genes) # Degradation rates\n",
    "    \n",
    "    # Cell-specific modulation of kinetics\n",
    "    cell_alpha_mod = 1 + 0.3 * np.random.randn(n_cells, 1)\n",
    "    cell_beta_mod = 1 + 0.2 * np.random.randn(n_cells, 1)\n",
    "    \n",
    "    # Simulate steady-state with noise\n",
    "    unspliced = (cell_alpha_mod * alpha_true) / (cell_beta_mod * beta_true) * base_expression\n",
    "    spliced = (cell_beta_mod * beta_true * unspliced) / gamma_true\n",
    "    \n",
    "    # Add noise\n",
    "    unspliced += np.random.gamma(0.1, 1, unspliced.shape)\n",
    "    spliced += np.random.gamma(0.1, 1, spliced.shape)\n",
    "    \n",
    "    # 4. ATAC-seq data with regulatory relationships\n",
    "    # Create peak-gene regulatory network\n",
    "    peak_gene_network = np.random.binomial(1, 0.15, (n_peaks, n_genes))\n",
    "    \n",
    "    # ATAC accessibility correlates with linked gene expression\n",
    "    atac_data = np.zeros((n_cells, n_peaks))\n",
    "    for peak in range(n_peaks):\n",
    "        linked_genes = peak_gene_network[peak, :] > 0\n",
    "        if linked_genes.sum() > 0:\n",
    "            # Accessibility correlates with average linked gene expression\n",
    "            gene_activity = spliced[:, linked_genes].mean(axis=1)\n",
    "            atac_data[:, peak] = 0.3 * gene_activity + 0.1 * np.random.gamma(1, 1, n_cells)\n",
    "        else:\n",
    "            atac_data[:, peak] = np.random.gamma(0.5, 1, n_cells)\n",
    "    \n",
    "    # Add spatial correlation to chromatin accessibility\n",
    "    for peak in range(0, n_peaks, 20):  # Every 20th peak\n",
    "        spatial_chrom = 0.2 * (1 + np.sin(2 * np.pi * x_coords / 50) * np.cos(2 * np.pi * y_coords / 50))\n",
    "        atac_data[:, peak] *= (1 + spatial_chrom)\n",
    "    \n",
    "    # 5. Create MuData-like structure\n",
    "    data = {\n",
    "        # Cell metadata\n",
    "        'obs': pd.DataFrame({\n",
    "            'cell_id': [f'cell_{i:04d}' for i in range(n_cells)],\n",
    "            'x_pixel': x_coords.astype(np.float32),\n",
    "            'y_pixel': y_coords.astype(np.float32),\n",
    "            'spatial_region': cell_regions,\n",
    "            'total_counts_rna': spliced.sum(axis=1) + unspliced.sum(axis=1),\n",
    "            'total_counts_atac': atac_data.sum(axis=1)\n",
    "        }),\n",
    "        \n",
    "        # Gene metadata\n",
    "        'var_rna': pd.DataFrame({\n",
    "            'gene_id': [f'gene_{i:04d}' for i in range(n_genes)],\n",
    "            'gene_name': [f'Gene{i}' for i in range(n_genes)],\n",
    "            'true_alpha': alpha_true,\n",
    "            'true_beta': beta_true,\n",
    "            'true_gamma': gamma_true\n",
    "        }),\n",
    "        \n",
    "        # Peak metadata\n",
    "        'var_atac': pd.DataFrame({\n",
    "            'peak_id': [f'peak_{i:04d}' for i in range(n_peaks)],\n",
    "            'chr': [f'chr{(i % 22) + 1}' for i in range(n_peaks)],\n",
    "            'start': np.random.randint(1000, 100000, n_peaks),\n",
    "            'end': np.random.randint(100000, 200000, n_peaks)\n",
    "        }),\n",
    "        \n",
    "        # Expression matrices\n",
    "        'spliced': spliced.astype(np.float32),\n",
    "        'unspliced': unspliced.astype(np.float32),\n",
    "        'atac': atac_data.astype(np.float32),\n",
    "        \n",
    "        # Ground truth\n",
    "        'peak_gene_network': peak_gene_network,\n",
    "        'spatial_regions': cell_regions,\n",
    "        'true_kinetics': {\n",
    "            'alpha': alpha_true,\n",
    "            'beta': beta_true, \n",
    "            'gamma': gamma_true\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Created data with {peak_gene_network.sum()} peak-gene regulatory links\")\n",
    "    print(f\"âœ“ Spatial structure: {n_regions} regions with {np.bincount(cell_regions)} cells each\")\n",
    "    print(f\"âœ“ Expression range - Spliced: [{spliced.min():.2f}, {spliced.max():.2f}]\")\n",
    "    print(f\"âœ“ Expression range - Unspliced: [{unspliced.min():.2f}, {unspliced.max():.2f}]\")\n",
    "    print(f\"âœ“ ATAC range: [{atac_data.min():.2f}, {atac_data.max():.2f}]\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Create demonstration data\n",
    "print(\"=== Creating Demonstration Data ===\")\n",
    "print(\"Note: In practice, load your own MuData with:\")\n",
    "print(\"  adata = mu.read('your_data.h5mu')\")\n",
    "print(\"  # Expected: adata.mod['rna'] with layers 'spliced', 'unspliced'\")\n",
    "print(\"  # Expected: adata.mod['atac'] with peak accessibility\")\n",
    "print(\"  # Expected: adata.obs with 'x_pixel', 'y_pixel' coordinates\\n\")\n",
    "\n",
    "# Use smaller data for demo (but show full scale structure)\n",
    "demo_data = create_stage3_synthetic_data(n_cells=300, n_genes=100, n_peaks=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "Validate the data format and check for required components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_stage3_data(data: Dict) -> Tuple[bool, list]:\n",
    "    \"\"\"\n",
    "    Validate data format for Stage 3 integrated model.\n",
    "    \n",
    "    Expected format:\n",
    "    - obs: DataFrame with 'x_pixel', 'y_pixel' columns\n",
    "    - spliced: (n_cells, n_genes) expression matrix\n",
    "    - unspliced: (n_cells, n_genes) expression matrix  \n",
    "    - atac: (n_cells, n_peaks) accessibility matrix\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    # Check required keys\n",
    "    required_keys = ['obs', 'spliced', 'unspliced', 'atac']\n",
    "    for key in required_keys:\n",
    "        if key not in data:\n",
    "            errors.append(f\"Missing required key: {key}\")\n",
    "    \n",
    "    if errors:\n",
    "        return False, errors\n",
    "    \n",
    "    # Check shapes\n",
    "    n_cells_obs = len(data['obs'])\n",
    "    n_cells_rna = data['spliced'].shape[0]\n",
    "    n_cells_atac = data['atac'].shape[0]\n",
    "    \n",
    "    if not (n_cells_obs == n_cells_rna == n_cells_atac):\n",
    "        errors.append(f\"Cell count mismatch: obs={n_cells_obs}, RNA={n_cells_rna}, ATAC={n_cells_atac}\")\n",
    "    \n",
    "    # Check gene dimensions\n",
    "    if data['spliced'].shape != data['unspliced'].shape:\n",
    "        errors.append(f\"Spliced/unspliced shape mismatch: {data['spliced'].shape} vs {data['unspliced'].shape}\")\n",
    "    \n",
    "    # Check spatial coordinates\n",
    "    required_coords = ['x_pixel', 'y_pixel']\n",
    "    for coord in required_coords:\n",
    "        if coord not in data['obs'].columns:\n",
    "            errors.append(f\"Missing spatial coordinate: {coord}\")\n",
    "    \n",
    "    # Check for NaN/infinite values\n",
    "    for matrix_name, matrix in [('spliced', data['spliced']), ('unspliced', data['unspliced']), ('atac', data['atac'])]:\n",
    "        if np.any(np.isnan(matrix)):\n",
    "            errors.append(f\"NaN values found in {matrix_name}\")\n",
    "        if np.any(np.isinf(matrix)):\n",
    "            errors.append(f\"Infinite values found in {matrix_name}\")\n",
    "        if np.any(matrix < 0):\n",
    "            errors.append(f\"Negative values found in {matrix_name}\")\n",
    "    \n",
    "    return len(errors) == 0, errors\n",
    "\n",
    "# Validate our demo data\n",
    "print(\"=== Data Validation ===\")\n",
    "is_valid, validation_errors = validate_stage3_data(demo_data)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"âœ“ Data validation passed!\")\n",
    "    \n",
    "    # Print data summary\n",
    "    n_cells = demo_data['spliced'].shape[0]\n",
    "    n_genes = demo_data['spliced'].shape[1] \n",
    "    n_peaks = demo_data['atac'].shape[1]\n",
    "    \n",
    "    print(f\"\\n=== Data Summary ===\")\n",
    "    print(f\"Cells: {n_cells:,}\")\n",
    "    print(f\"Genes: {n_genes:,}\")\n",
    "    print(f\"ATAC peaks: {n_peaks:,}\")\n",
    "    \n",
    "    print(f\"\\n=== Expression Statistics ===\")\n",
    "    print(f\"Spliced - mean: {demo_data['spliced'].mean():.2f}, std: {demo_data['spliced'].std():.2f}\")\n",
    "    print(f\"Unspliced - mean: {demo_data['unspliced'].mean():.2f}, std: {demo_data['unspliced'].std():.2f}\")\n",
    "    print(f\"ATAC - mean: {demo_data['atac'].mean():.2f}, std: {demo_data['atac'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\n=== Spatial Coordinates ===\")\n",
    "    x_range = (demo_data['obs']['x_pixel'].min(), demo_data['obs']['x_pixel'].max())\n",
    "    y_range = (demo_data['obs']['y_pixel'].min(), demo_data['obs']['y_pixel'].max())\n",
    "    print(f\"X range: [{x_range[0]:.1f}, {x_range[1]:.1f}]\")\n",
    "    print(f\"Y range: [{y_range[0]:.1f}, {y_range[1]:.1f}]\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Data validation failed!\")\n",
    "    for error in validation_errors:\n",
    "        print(f\"  - {error}\")\n",
    "    print(\"\\nPlease fix data format before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Modal Data Visualization\n",
    "\n",
    "Explore the data structure and relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Spatial distribution of cells\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "scatter = ax1.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'], \n",
    "                     c=demo_data['obs']['spatial_region'], cmap='Set1', \n",
    "                     s=8, alpha=0.7)\n",
    "ax1.set_xlabel('X Pixel')\n",
    "ax1.set_ylabel('Y Pixel')\n",
    "ax1.set_title('Spatial Cell Distribution')\n",
    "plt.colorbar(scatter, ax=ax1, label='Region')\n",
    "\n",
    "# 2. Total RNA counts spatial distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "scatter2 = ax2.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "                      c=demo_data['obs']['total_counts_rna'], cmap='viridis',\n",
    "                      s=8, alpha=0.7)\n",
    "ax2.set_xlabel('X Pixel')\n",
    "ax2.set_ylabel('Y Pixel')\n",
    "ax2.set_title('Total RNA Counts (Spatial)')\n",
    "plt.colorbar(scatter2, ax=ax2, label='RNA Counts')\n",
    "\n",
    "# 3. ATAC accessibility spatial distribution  \n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "scatter3 = ax3.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "                      c=demo_data['obs']['total_counts_atac'], cmap='plasma',\n",
    "                      s=8, alpha=0.7)\n",
    "ax3.set_xlabel('X Pixel')\n",
    "ax3.set_ylabel('Y Pixel')\n",
    "ax3.set_title('Total ATAC Counts (Spatial)')\n",
    "plt.colorbar(scatter3, ax=ax3, label='ATAC Counts')\n",
    "\n",
    "# 4. Spliced vs Unspliced correlation\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "total_spliced = demo_data['spliced'].sum(axis=1)\n",
    "total_unspliced = demo_data['unspliced'].sum(axis=1)\n",
    "ax4.scatter(total_spliced, total_unspliced, alpha=0.6, s=8)\n",
    "ax4.set_xlabel('Total Spliced')\n",
    "ax4.set_ylabel('Total Unspliced')\n",
    "correlation = np.corrcoef(total_spliced, total_unspliced)[0, 1]\n",
    "ax4.set_title(f'Spliced vs Unspliced\\n(r = {correlation:.3f})')\n",
    "ax4.plot([total_spliced.min(), total_spliced.max()], \n",
    "         [total_unspliced.min(), total_unspliced.max()], 'r--', alpha=0.5)\n",
    "\n",
    "# 5. Gene expression heatmap (top variable genes)\n",
    "ax5 = fig.add_subplot(gs[1, :2])\n",
    "gene_var = demo_data['spliced'].var(axis=0)\n",
    "top_genes_idx = np.argsort(gene_var)[-20:]  # Top 20 variable genes\n",
    "expr_subset = demo_data['spliced'][:, top_genes_idx].T\n",
    "im1 = ax5.imshow(expr_subset, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "ax5.set_xlabel('Cells')\n",
    "ax5.set_ylabel('Genes (Top 20 Variable)')\n",
    "ax5.set_title('Gene Expression Heatmap')\n",
    "plt.colorbar(im1, ax=ax5, label='Expression')\n",
    "\n",
    "# 6. ATAC accessibility heatmap (top variable peaks)\n",
    "ax6 = fig.add_subplot(gs[1, 2:])\n",
    "peak_var = demo_data['atac'].var(axis=0)\n",
    "top_peaks_idx = np.argsort(peak_var)[-20:]  # Top 20 variable peaks\n",
    "atac_subset = demo_data['atac'][:, top_peaks_idx].T\n",
    "im2 = ax6.imshow(atac_subset, cmap='plasma', aspect='auto', interpolation='nearest')\n",
    "ax6.set_xlabel('Cells')\n",
    "ax6.set_ylabel('Peaks (Top 20 Variable)')\n",
    "ax6.set_title('ATAC Accessibility Heatmap')\n",
    "plt.colorbar(im2, ax=ax6, label='Accessibility')\n",
    "\n",
    "# 7. Peak-gene regulatory network structure\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "# Show a subset of the regulatory network\n",
    "network_subset = demo_data['peak_gene_network'][:30, :30]\n",
    "im3 = ax7.imshow(network_subset, cmap='Blues', aspect='auto')\n",
    "ax7.set_xlabel('Genes')\n",
    "ax7.set_ylabel('Peaks')\n",
    "ax7.set_title('Peak-Gene Network (Subset)')\n",
    "plt.colorbar(im3, ax=ax7, shrink=0.8)\n",
    "\n",
    "# 8. Expression-accessibility correlation\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "# Correlate mean gene expression with mean linked peak accessibility\n",
    "gene_expr_mean = demo_data['spliced'].mean(axis=0)\n",
    "gene_linked_peaks = demo_data['peak_gene_network'].sum(axis=0)  # Number of linked peaks per gene\n",
    "ax8.scatter(gene_linked_peaks, gene_expr_mean, alpha=0.6, s=15)\n",
    "ax8.set_xlabel('Number of Linked Peaks')\n",
    "ax8.set_ylabel('Mean Gene Expression')\n",
    "link_expr_corr = np.corrcoef(gene_linked_peaks, gene_expr_mean)[0, 1]\n",
    "ax8.set_title(f'Regulatory Links vs Expression\\n(r = {link_expr_corr:.3f})')\n",
    "\n",
    "# 9. Velocity phase space (example genes)\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "# Show phase space for a few example genes\n",
    "example_genes = [10, 25, 40]  # Select a few genes\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, gene_idx in enumerate(example_genes):\n",
    "    ax9.scatter(demo_data['spliced'][:, gene_idx], demo_data['unspliced'][:, gene_idx],\n",
    "               alpha=0.5, s=8, c=colors[i], label=f'Gene {gene_idx}')\n",
    "ax9.set_xlabel('Spliced Expression')\n",
    "ax9.set_ylabel('Unspliced Expression')\n",
    "ax9.set_title('Velocity Phase Space')\n",
    "ax9.legend()\n",
    "\n",
    "# 10. Data quality metrics\n",
    "ax10 = fig.add_subplot(gs[2, 3])\n",
    "metrics = {\n",
    "    'Genes\\nDetected': (demo_data['spliced'] > 0).sum(axis=1).mean(),\n",
    "    'Peaks\\nDetected': (demo_data['atac'] > 0).sum(axis=1).mean(),\n",
    "    'RNA\\nSpatial Var': demo_data['obs']['total_counts_rna'].var(),\n",
    "    'ATAC\\nSpatial Var': demo_data['obs']['total_counts_atac'].var()\n",
    "}\n",
    "bars = ax10.bar(range(len(metrics)), [v/1000 if v > 1000 else v for v in metrics.values()])\n",
    "ax10.set_xticks(range(len(metrics)))\n",
    "ax10.set_xticklabels(metrics.keys(), rotation=45, ha='right')\n",
    "ax10.set_ylabel('Value (scaled)')\n",
    "ax10.set_title('Data Quality Metrics')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, (name, value)) in enumerate(zip(bars, metrics.items())):\n",
    "    if value > 1000:\n",
    "        ax10.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{value:.0f}', ha='center', va='bottom', fontsize=8)\n",
    "    else:\n",
    "        ax10.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{value:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Stage 3 Multi-Modal Data Overview', fontsize=16, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Multi-Modal Data Summary ===\")\n",
    "print(f\"ðŸ“Š Regulatory network density: {demo_data['peak_gene_network'].mean():.3f}\")\n",
    "print(f\"ðŸ§¬ Average genes per cell: {(demo_data['spliced'] > 0).sum(axis=1).mean():.1f}\")\n",
    "print(f\"ðŸ”¬ Average peaks per cell: {(demo_data['atac'] > 0).sum(axis=1).mean():.1f}\")\n",
    "print(f\"ðŸ“ Spatial range: X=[{demo_data['obs']['x_pixel'].min():.1f}, {demo_data['obs']['x_pixel'].max():.1f}], Y=[{demo_data['obs']['y_pixel'].min():.1f}, {demo_data['obs']['y_pixel'].max():.1f}]\")\n",
    "print(f\"ðŸ”— Peak-gene correlations ready for integrated modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Modal Graph Construction\n",
    "\n",
    "Build spatial and expression graphs for Stage 3 integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH and HAS_TORCH_GEOMETRIC:\n",
    "    # Use real graph construction\n",
    "    from tangelo_velocity.preprocessing.graph_builder import GraphBuilder\n",
    "    \n",
    "    print(\"=== Building Multi-Modal Graphs ===\")\n",
    "    \n",
    "    # Initialize graph builder\n",
    "    graph_builder = GraphBuilder(config)\n",
    "    \n",
    "    # Prepare data\n",
    "    spatial_coords = demo_data['obs'][['x_pixel', 'y_pixel']].values\n",
    "    expression_data = demo_data['spliced']\n",
    "    \n",
    "    # Build spatial graph\n",
    "    print(\"Building spatial k-NN graph...\")\n",
    "    spatial_graph = graph_builder.build_spatial_graph(\n",
    "        spatial_coords=spatial_coords,\n",
    "        k=config.graph.spatial_k,\n",
    "        metric=config.graph.spatial_metric\n",
    "    )\n",
    "    \n",
    "    # Build expression graph\n",
    "    print(\"Building expression similarity graph...\")\n",
    "    expression_graph = graph_builder.build_expression_graph(\n",
    "        expression_data=expression_data,\n",
    "        k=config.graph.expression_k,\n",
    "        metric=config.graph.expression_metric\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Spatial graph: {spatial_graph['n_nodes']} nodes, {spatial_graph['n_edges']} edges\")\n",
    "    print(f\"âœ“ Expression graph: {expression_graph['n_nodes']} nodes, {expression_graph['n_edges']} edges\")\n",
    "    \n",
    "    # Store graph information\n",
    "    graphs = {\n",
    "        'spatial': spatial_graph,\n",
    "        'expression': expression_graph\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    # Mock graph construction for demonstration\n",
    "    print(\"=== Mock Graph Construction (PyTorch Geometric not available) ===\")\n",
    "    \n",
    "    n_cells = len(demo_data['obs'])\n",
    "    \n",
    "    # Mock spatial graph (k-NN based on coordinates)\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    # Spatial k-NN\n",
    "    spatial_coords = demo_data['obs'][['x_pixel', 'y_pixel']].values\n",
    "    spatial_knn = NearestNeighbors(n_neighbors=config.graph.spatial_k + 1, metric='euclidean')\n",
    "    spatial_knn.fit(spatial_coords)\n",
    "    spatial_distances, spatial_indices = spatial_knn.kneighbors(spatial_coords)\n",
    "    \n",
    "    # Create edge list (exclude self-connections)\n",
    "    spatial_edges = []\n",
    "    for i in range(n_cells):\n",
    "        for j in spatial_indices[i, 1:]:  # Skip first (self)\n",
    "            spatial_edges.append([i, j])\n",
    "    \n",
    "    # Expression k-NN  \n",
    "    expr_knn = NearestNeighbors(n_neighbors=config.graph.expression_k + 1, metric='cosine')\n",
    "    expr_knn.fit(demo_data['spliced'])\n",
    "    expr_distances, expr_indices = expr_knn.kneighbors(demo_data['spliced'])\n",
    "    \n",
    "    expr_edges = []\n",
    "    for i in range(n_cells):\n",
    "        for j in expr_indices[i, 1:]:  # Skip first (self)\n",
    "            expr_edges.append([i, j])\n",
    "    \n",
    "    # Mock graph structure\n",
    "    graphs = {\n",
    "        'spatial': {\n",
    "            'edge_index': np.array(spatial_edges).T,\n",
    "            'edge_weights': np.ones(len(spatial_edges)),\n",
    "            'n_nodes': n_cells,\n",
    "            'n_edges': len(spatial_edges)\n",
    "        },\n",
    "        'expression': {\n",
    "            'edge_index': np.array(expr_edges).T,\n",
    "            'edge_weights': np.ones(len(expr_edges)),\n",
    "            'n_nodes': n_cells,\n",
    "            'n_edges': len(expr_edges)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Mock spatial graph: {graphs['spatial']['n_nodes']} nodes, {graphs['spatial']['n_edges']} edges\")\n",
    "    print(f\"âœ“ Mock expression graph: {graphs['expression']['n_nodes']} nodes, {graphs['expression']['n_edges']} edges\")\n",
    "\n",
    "# Visualize graph connectivity\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 1. Spatial graph visualization\n",
    "ax1 = axes[0]\n",
    "# Plot cells\n",
    "ax1.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'], \n",
    "           c='lightblue', s=20, alpha=0.7, zorder=2)\n",
    "\n",
    "# Plot edges (sample subset for visibility)\n",
    "edge_subset = graphs['spatial']['edge_index'][:, ::10]  # Every 10th edge\n",
    "for i in range(edge_subset.shape[1]):\n",
    "    cell1, cell2 = edge_subset[:, i]\n",
    "    x1, y1 = spatial_coords[cell1]\n",
    "    x2, y2 = spatial_coords[cell2]\n",
    "    ax1.plot([x1, x2], [y1, y2], 'gray', alpha=0.3, linewidth=0.5, zorder=1)\n",
    "\n",
    "ax1.set_xlabel('X Pixel')\n",
    "ax1.set_ylabel('Y Pixel')\n",
    "ax1.set_title(f'Spatial Graph\\n(k={config.graph.spatial_k})')\n",
    "\n",
    "# 2. Graph connectivity statistics\n",
    "ax2 = axes[1]\n",
    "# Compute degree distributions\n",
    "spatial_degrees = np.bincount(graphs['spatial']['edge_index'].flatten())\n",
    "expr_degrees = np.bincount(graphs['expression']['edge_index'].flatten())\n",
    "\n",
    "ax2.hist(spatial_degrees, bins=20, alpha=0.7, label='Spatial', density=True)\n",
    "ax2.hist(expr_degrees, bins=20, alpha=0.7, label='Expression', density=True)\n",
    "ax2.set_xlabel('Node Degree')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Graph Degree Distributions')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Graph properties comparison\n",
    "ax3 = axes[2]\n",
    "properties = {\n",
    "    'Spatial\\nNodes': graphs['spatial']['n_nodes'],\n",
    "    'Spatial\\nEdges': graphs['spatial']['n_edges'],\n",
    "    'Expr\\nNodes': graphs['expression']['n_nodes'],\n",
    "    'Expr\\nEdges': graphs['expression']['n_edges'],\n",
    "    'Spatial\\nDensity': graphs['spatial']['n_edges'] / (graphs['spatial']['n_nodes'] * (graphs['spatial']['n_nodes'] - 1)) * 100,\n",
    "    'Expr\\nDensity': graphs['expression']['n_edges'] / (graphs['expression']['n_nodes'] * (graphs['expression']['n_nodes'] - 1)) * 100\n",
    "}\n",
    "\n",
    "# Normalize for visualization\n",
    "normalized_props = {}\n",
    "for key, value in properties.items():\n",
    "    if 'Density' in key:\n",
    "        normalized_props[key] = value  # Keep densities as percentages\n",
    "    else:\n",
    "        normalized_props[key] = value / 100  # Scale down counts\n",
    "\n",
    "bars = ax3.bar(range(len(normalized_props)), normalized_props.values())\n",
    "ax3.set_xticks(range(len(normalized_props)))\n",
    "ax3.set_xticklabels(normalized_props.keys(), rotation=45, ha='right')\n",
    "ax3.set_ylabel('Value (scaled)')\n",
    "ax3.set_title('Graph Properties')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, (name, value)) in enumerate(zip(bars, properties.items())):\n",
    "    if 'Density' in name:\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{value:.2f}%', ha='center', va='bottom', fontsize=8)\n",
    "    else:\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f'{int(value)}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Graph Construction Summary ===\")\n",
    "print(f\"ðŸ•¸ï¸  Spatial graph density: {graphs['spatial']['n_edges'] / (graphs['spatial']['n_nodes'] * graphs['spatial']['n_nodes']) * 100:.3f}%\")\n",
    "print(f\"ðŸ§¬ Expression graph density: {graphs['expression']['n_edges'] / (graphs['expression']['n_nodes'] * graphs['expression']['n_nodes']) * 100:.3f}%\")\n",
    "print(f\"ðŸ“Š Average spatial degree: {spatial_degrees.mean():.1f}\")\n",
    "print(f\"ðŸ“Š Average expression degree: {expr_degrees.mean():.1f}\")\n",
    "print(f\"âœ… Graphs ready for Stage 3 integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 Model Implementation\n",
    "\n",
    "Initialize and demonstrate the integrated model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 model implementation (mock if not available)\n",
    "if HAS_STAGE3 and HAS_TORCH and HAS_TORCH_GEOMETRIC:\n",
    "    # Real Stage 3 implementation\n",
    "    print(\"=== Initializing Stage 3 Integrated Model ===\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Update config with data dimensions\n",
    "    config.gene_dim = demo_data['spliced'].shape[1]\n",
    "    config.atac_dim = demo_data['atac'].shape[1]\n",
    "    \n",
    "    # Initialize Stage 3 model\n",
    "    model = Stage3IntegratedModel(\n",
    "        config=config,\n",
    "        gene_dim=config.gene_dim,\n",
    "        atac_dim=config.atac_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"âœ“ Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "else:\n",
    "    # Mock Stage 3 implementation for demonstration\n",
    "    print(\"=== Mock Stage 3 Implementation ===\")\n",
    "    print(\"Stage 3 not yet implemented - demonstrating architecture concept\")\n",
    "    \n",
    "    class MockStage3Model:\n",
    "        \"\"\"\n",
    "        Mock Stage 3 integrated model for demonstration.\n",
    "        Shows the conceptual architecture without full implementation.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self, config, gene_dim, atac_dim):\n",
    "            self.config = config\n",
    "            self.gene_dim = gene_dim\n",
    "            self.atac_dim = atac_dim\n",
    "            \n",
    "            print(f\"ðŸ“‹ Mock Stage 3 Architecture:\")\n",
    "            print(f\"   - Gene dimension: {gene_dim}\")\n",
    "            print(f\"   - ATAC dimension: {atac_dim}\")\n",
    "            print(f\"   - Regulatory components: Sigmoid features + Linear interactions\")\n",
    "            print(f\"   - Graph components: Spatial + Expression GraphSAGE\")\n",
    "            print(f\"   - Fusion method: {config.graph.fusion_method}\")\n",
    "            \n",
    "            # Mock component specifications\n",
    "            self.components = {\n",
    "                'sigmoid_features': {\n",
    "                    'n_genes': gene_dim,\n",
    "                    'n_components': config.regulatory.n_sigmoid_components,\n",
    "                    'description': 'Learnable sigmoid transformation: Î± = W(sigmoid(s))'\n",
    "                },\n",
    "                'regulatory_network': {\n",
    "                    'interaction_matrix': f'{gene_dim}x{gene_dim}',\n",
    "                    'atac_masking': config.regulatory.use_atac_masking,\n",
    "                    'description': 'Linear interactions with ATAC masking'\n",
    "                },\n",
    "                'spatial_encoder': {\n",
    "                    'input_dim': gene_dim + 2,  # +2 for x,y coordinates\n",
    "                    'latent_dim': config.graph.spatial_latent_dim,\n",
    "                    'hidden_dims': config.graph.hidden_dims,\n",
    "                    'description': 'GraphSAGE on spatial k-NN graph'\n",
    "                },\n",
    "                'expression_encoder': {\n",
    "                    'input_dim': gene_dim,\n",
    "                    'latent_dim': config.graph.expression_latent_dim,\n",
    "                    'hidden_dims': config.graph.hidden_dims,\n",
    "                    'description': 'GraphSAGE on expression similarity graph'\n",
    "                },\n",
    "                'fusion_module': {\n",
    "                    'method': config.graph.fusion_method,\n",
    "                    'input_dims': f'{config.graph.spatial_latent_dim} + {config.graph.expression_latent_dim}',\n",
    "                    'output_dim': gene_dim,\n",
    "                    'description': f'{config.graph.fusion_method.title()} fusion of graph embeddings'\n",
    "                },\n",
    "                'ode_system': {\n",
    "                    'solver': config.ode.solver,\n",
    "                    'equations': 'ds/dt = Î±_integrated - Î²s, du/dt = Î²s - Î³u',\n",
    "                    'description': 'ODE system with integrated transcription rates'\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def get_architecture_summary(self):\n",
    "            \"\"\"Return detailed architecture summary.\"\"\"\n",
    "            return self.components\n",
    "        \n",
    "        def forward_simulation(self, data):\n",
    "            \"\"\"Simulate forward pass for demonstration.\"\"\"\n",
    "            n_cells, n_genes = data['spliced'].shape\n",
    "            \n",
    "            # Mock outputs\n",
    "            results = {\n",
    "                'regulatory_alpha': np.random.gamma(1.5, 1, (n_cells, n_genes)),\n",
    "                'spatial_embedding': np.random.randn(n_cells, config.graph.spatial_latent_dim),\n",
    "                'expression_embedding': np.random.randn(n_cells, config.graph.expression_latent_dim),\n",
    "                'fused_alpha': np.random.gamma(1.2, 1, (n_cells, n_genes)),\n",
    "                'velocity': np.random.randn(n_cells, n_genes) * 0.1,\n",
    "                'beta_params': np.random.gamma(2, 0.5, n_genes),\n",
    "                'gamma_params': np.random.gamma(1.5, 0.3, n_genes)\n",
    "            }\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    # Initialize mock model\n",
    "    model = MockStage3Model(\n",
    "        config=config,\n",
    "        gene_dim=demo_data['spliced'].shape[1],\n",
    "        atac_dim=demo_data['atac'].shape[1]\n",
    "    )\n",
    "\n",
    "# Display model architecture\n",
    "print(f\"\\n=== Stage 3 Architecture Overview ===\")\n",
    "if hasattr(model, 'get_architecture_summary'):\n",
    "    components = model.get_architecture_summary()\n",
    "    \n",
    "    for comp_name, comp_info in components.items():\n",
    "        print(f\"\\nðŸ”§ {comp_name.replace('_', ' ').title()}:\")\n",
    "        print(f\"   ðŸ“ {comp_info['description']}\")\n",
    "        for key, value in comp_info.items():\n",
    "            if key != 'description':\n",
    "                print(f\"   ðŸ“Š {key}: {value}\")\n",
    "else:\n",
    "    print(\"Real Stage 3 model initialized - architecture details in model.summary()\")\n",
    "\n",
    "print(f\"\\nâœ… Stage 3 model ready for training and velocity estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Simulation\n",
    "\n",
    "Demonstrate the training process for the integrated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training simulation\n",
    "print(\"=== Stage 3 Training Simulation ===\")\n",
    "\n",
    "def simulate_stage3_training(model, data, config, n_epochs=20):\n",
    "    \"\"\"\n",
    "    Simulate Stage 3 training process with realistic loss curves.\n",
    "    \"\"\"\n",
    "    print(f\"Simulating {n_epochs} epochs of Stage 3 training...\")\n",
    "    \n",
    "    # Initialize training metrics\n",
    "    metrics = {\n",
    "        'total_loss': [],\n",
    "        'regulatory_loss': [],\n",
    "        'graph_loss': [],\n",
    "        'fusion_loss': [],\n",
    "        'kl_loss': [],\n",
    "        'reconstruction_loss': []\n",
    "    }\n",
    "    \n",
    "    # Simulate training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        # Simulate realistic loss decay with noise\n",
    "        base_decay = np.exp(-epoch * 0.1)\n",
    "        noise = 1 + 0.1 * np.random.randn()\n",
    "        \n",
    "        # Component losses with different decay rates\n",
    "        reg_loss = (5.0 * base_decay + 1.0) * noise\n",
    "        graph_loss = (3.0 * base_decay + 0.8) * noise\n",
    "        fusion_loss = (2.0 * base_decay + 0.5) * noise\n",
    "        kl_loss = (1.0 * base_decay + 0.2) * noise\n",
    "        recon_loss = (4.0 * base_decay + 1.2) * noise\n",
    "        \n",
    "        # Weighted total loss\n",
    "        total_loss = (\n",
    "            config.training.regulatory_weight * reg_loss +\n",
    "            config.training.graph_weight * graph_loss +\n",
    "            config.training.fusion_weight * fusion_loss +\n",
    "            config.training.kl_weight * kl_loss +\n",
    "            recon_loss\n",
    "        )\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['total_loss'].append(total_loss)\n",
    "        metrics['regulatory_loss'].append(reg_loss)\n",
    "        metrics['graph_loss'].append(graph_loss)\n",
    "        metrics['fusion_loss'].append(fusion_loss)\n",
    "        metrics['kl_loss'].append(kl_loss)\n",
    "        metrics['reconstruction_loss'].append(recon_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 5 == 0 or epoch == n_epochs - 1:\n",
    "            print(f\"Epoch {epoch+1:2d}/{n_epochs}: \"\n",
    "                  f\"Total={total_loss:.3f}, \"\n",
    "                  f\"Reg={reg_loss:.3f}, \"\n",
    "                  f\"Graph={graph_loss:.3f}, \"\n",
    "                  f\"Fusion={fusion_loss:.3f}, \"\n",
    "                  f\"Recon={recon_loss:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run training simulation\n",
    "training_metrics = simulate_stage3_training(model, demo_data, config, n_epochs=50)\n",
    "\n",
    "# Visualize training progress\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# 1. Total loss curve\n",
    "ax1 = axes[0, 0]\n",
    "epochs = range(1, len(training_metrics['total_loss']) + 1)\n",
    "ax1.plot(epochs, training_metrics['total_loss'], 'b-', linewidth=2, label='Total Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Total Training Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Component losses\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(epochs, training_metrics['regulatory_loss'], label='Regulatory', alpha=0.8)\n",
    "ax2.plot(epochs, training_metrics['graph_loss'], label='Graph', alpha=0.8)\n",
    "ax2.plot(epochs, training_metrics['fusion_loss'], label='Fusion', alpha=0.8)\n",
    "ax2.plot(epochs, training_metrics['reconstruction_loss'], label='Reconstruction', alpha=0.8)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Component Losses')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Loss convergence rates\n",
    "ax3 = axes[1, 0]\n",
    "# Calculate relative improvement\n",
    "improvement_rates = {}\n",
    "for loss_name, loss_values in training_metrics.items():\n",
    "    if len(loss_values) > 10:\n",
    "        initial = np.mean(loss_values[:5])\n",
    "        final = np.mean(loss_values[-5:])\n",
    "        improvement_rates[loss_name.replace('_', '\\n')] = (initial - final) / initial * 100\n",
    "\n",
    "bars = ax3.bar(range(len(improvement_rates)), improvement_rates.values())\n",
    "ax3.set_xticks(range(len(improvement_rates)))\n",
    "ax3.set_xticklabels(improvement_rates.keys(), rotation=45, ha='right')\n",
    "ax3.set_ylabel('Improvement (%)')\n",
    "ax3.set_title('Loss Reduction by Component')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, improvement_rates.values()):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "             f'{value:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 4. Training stability (loss variance)\n",
    "ax4 = axes[1, 1]\n",
    "loss_variance = {}\n",
    "for loss_name, loss_values in training_metrics.items():\n",
    "    if 'loss' in loss_name:\n",
    "        # Calculate rolling variance (stability)\n",
    "        rolling_var = np.array([np.var(loss_values[max(0, i-5):i+1]) for i in range(len(loss_values))])\n",
    "        loss_variance[loss_name.replace('_loss', '')] = rolling_var\n",
    "\n",
    "for name, variance in loss_variance.items():\n",
    "    ax4.plot(epochs, variance, label=name.title(), alpha=0.7)\n",
    "\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Loss Variance')\n",
    "ax4.set_title('Training Stability')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Training Summary ===\")\n",
    "final_loss = training_metrics['total_loss'][-1]\n",
    "initial_loss = training_metrics['total_loss'][0]\n",
    "improvement = (initial_loss - final_loss) / initial_loss * 100\n",
    "\n",
    "print(f\"ðŸ“Š Initial loss: {initial_loss:.3f}\")\n",
    "print(f\"ðŸ“Š Final loss: {final_loss:.3f}\")\n",
    "print(f\"ðŸ“ˆ Overall improvement: {improvement:.1f}%\")\n",
    "print(f\"âš¡ Loss weights - Regulatory: {config.training.regulatory_weight}, Graph: {config.training.graph_weight}, Fusion: {config.training.fusion_weight}\")\n",
    "print(f\"âœ… Stage 3 training completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity Estimation and Predictions\n",
    "\n",
    "Generate integrated velocity predictions using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity estimation\n",
    "print(\"=== Stage 3 Velocity Estimation ===\")\n",
    "\n",
    "# Generate predictions (mock or real)\n",
    "if hasattr(model, 'forward_simulation'):\n",
    "    # Mock predictions\n",
    "    print(\"Generating mock Stage 3 predictions...\")\n",
    "    predictions = model.forward_simulation(demo_data)\n",
    "    \n",
    "else:\n",
    "    # Real model predictions (if implemented)\n",
    "    print(\"Generating real Stage 3 predictions...\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Convert data to tensors\n",
    "        spliced = torch.tensor(demo_data['spliced'], dtype=torch.float32)\n",
    "        unspliced = torch.tensor(demo_data['unspliced'], dtype=torch.float32)\n",
    "        atac = torch.tensor(demo_data['atac'], dtype=torch.float32)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model(spliced, unspliced, atac=atac, **graphs)\n",
    "\n",
    "print(f\"âœ“ Generated predictions for {len(demo_data['obs'])} cells\")\n",
    "\n",
    "# Extract key predictions\n",
    "velocity = predictions['velocity']\n",
    "regulatory_alpha = predictions['regulatory_alpha']\n",
    "fused_alpha = predictions['fused_alpha']\n",
    "spatial_embedding = predictions['spatial_embedding']\n",
    "expression_embedding = predictions['expression_embedding']\n",
    "\n",
    "print(f\"ðŸ“Š Velocity shape: {velocity.shape}\")\n",
    "print(f\"ðŸ“Š Regulatory Î± shape: {regulatory_alpha.shape}\")\n",
    "print(f\"ðŸ“Š Fused Î± shape: {fused_alpha.shape}\")\n",
    "print(f\"ðŸ“Š Spatial embedding shape: {spatial_embedding.shape}\")\n",
    "print(f\"ðŸ“Š Expression embedding shape: {expression_embedding.shape}\")\n",
    "\n",
    "# Comprehensive velocity visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Velocity magnitude spatial distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "velocity_magnitude = np.linalg.norm(velocity, axis=1)\n",
    "scatter1 = ax1.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "                      c=velocity_magnitude, cmap='viridis', s=15, alpha=0.7)\n",
    "ax1.set_xlabel('X Pixel')\n",
    "ax1.set_ylabel('Y Pixel')\n",
    "ax1.set_title('Velocity Magnitude (Spatial)')\n",
    "plt.colorbar(scatter1, ax=ax1, label='|Velocity|')\n",
    "\n",
    "# 2. Regulatory vs fused transcription rates\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "reg_alpha_mean = regulatory_alpha.mean(axis=1)\n",
    "fused_alpha_mean = fused_alpha.mean(axis=1)\n",
    "ax2.scatter(reg_alpha_mean, fused_alpha_mean, alpha=0.6, s=15)\n",
    "ax2.set_xlabel('Regulatory Î± (mean)')\n",
    "ax2.set_ylabel('Fused Î± (mean)')\n",
    "correlation = np.corrcoef(reg_alpha_mean, fused_alpha_mean)[0, 1]\n",
    "ax2.set_title(f'Regulatory vs Fused Î±\\n(r = {correlation:.3f})')\n",
    "# Add diagonal reference line\n",
    "min_val, max_val = min(reg_alpha_mean.min(), fused_alpha_mean.min()), max(reg_alpha_mean.max(), fused_alpha_mean.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5)\n",
    "\n",
    "# 3. Spatial embedding UMAP-style visualization\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "# Simple 2D projection of spatial embeddings (first 2 components)\n",
    "if spatial_embedding.shape[1] >= 2:\n",
    "    scatter3 = ax3.scatter(spatial_embedding[:, 0], spatial_embedding[:, 1],\n",
    "                          c=demo_data['obs']['spatial_region'], cmap='Set1', s=15, alpha=0.7)\n",
    "    ax3.set_xlabel('Spatial Embed Dim 1')\n",
    "    ax3.set_ylabel('Spatial Embed Dim 2')\n",
    "    ax3.set_title('Spatial Graph Embedding')\n",
    "    plt.colorbar(scatter3, ax=ax3, label='Region')\n",
    "\n",
    "# 4. Expression embedding visualization\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "if expression_embedding.shape[1] >= 2:\n",
    "    scatter4 = ax4.scatter(expression_embedding[:, 0], expression_embedding[:, 1],\n",
    "                          c=velocity_magnitude, cmap='plasma', s=15, alpha=0.7)\n",
    "    ax4.set_xlabel('Expr Embed Dim 1')\n",
    "    ax4.set_ylabel('Expr Embed Dim 2')\n",
    "    ax4.set_title('Expression Graph Embedding')\n",
    "    plt.colorbar(scatter4, ax=ax4, label='|Velocity|')\n",
    "\n",
    "# 5. Velocity field visualization (subset of genes)\n",
    "ax5 = fig.add_subplot(gs[1, :2])\n",
    "# Select top variable genes for velocity field\n",
    "gene_velocity_var = velocity.var(axis=0)\n",
    "top_velocity_genes = np.argsort(gene_velocity_var)[-10:]  # Top 10\n",
    "\n",
    "# Create velocity field plot\n",
    "n_arrows = 30  # Subsample for visualization\n",
    "arrow_indices = np.random.choice(len(demo_data['obs']), n_arrows, replace=False)\n",
    "\n",
    "for i, cell_idx in enumerate(arrow_indices):\n",
    "    x, y = demo_data['obs']['x_pixel'].iloc[cell_idx], demo_data['obs']['y_pixel'].iloc[cell_idx]\n",
    "    # Average velocity across top genes for this cell\n",
    "    vel_x = velocity[cell_idx, top_velocity_genes].mean() * 5  # Scale for visibility\n",
    "    vel_y = velocity_magnitude[cell_idx] * np.sin(i * 0.5) * 2  # Add some y-component\n",
    "    \n",
    "    ax5.arrow(x, y, vel_x, vel_y, head_width=1.5, head_length=1.0, \n",
    "             fc='red', ec='red', alpha=0.6, length_includes_head=True)\n",
    "\n",
    "# Add background scatter\n",
    "ax5.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "           c='lightblue', s=10, alpha=0.5, zorder=1)\n",
    "ax5.set_xlabel('X Pixel')\n",
    "ax5.set_ylabel('Y Pixel')\n",
    "ax5.set_title('Integrated Velocity Field')\n",
    "\n",
    "# 6. Gene-wise velocity comparison\n",
    "ax6 = fig.add_subplot(gs[1, 2:])\n",
    "# Compare velocity predictions for example genes\n",
    "example_genes = [10, 25, 40, 55]  # Select a few genes\n",
    "for i, gene_idx in enumerate(example_genes):\n",
    "    ax6.scatter(demo_data['spliced'][:, gene_idx], velocity[:, gene_idx],\n",
    "               alpha=0.6, s=8, label=f'Gene {gene_idx}')\n",
    "\n",
    "ax6.set_xlabel('Spliced Expression')\n",
    "ax6.set_ylabel('Velocity')\n",
    "ax6.set_title('Velocity vs Expression\\n(Example Genes)')\n",
    "ax6.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax6.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 7. Integration comparison: Regulatory vs Graph contributions\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "# Compute approximate contributions (simplified)\n",
    "regulatory_contribution = np.abs(regulatory_alpha - fused_alpha).mean(axis=1)\n",
    "graph_contribution = velocity_magnitude  # Proxy for graph influence\n",
    "\n",
    "ax7.scatter(regulatory_contribution, graph_contribution, alpha=0.6, s=15,\n",
    "           c=demo_data['obs']['spatial_region'], cmap='Set1')\n",
    "ax7.set_xlabel('Regulatory Contribution')\n",
    "ax7.set_ylabel('Graph Contribution (Proxy)')\n",
    "ax7.set_title('Integration Balance')\n",
    "\n",
    "# 8. Model confidence/uncertainty visualization\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "# Use velocity variance as uncertainty proxy\n",
    "velocity_uncertainty = velocity.var(axis=1)\n",
    "ax8.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "           c=velocity_uncertainty, cmap='Reds', s=15, alpha=0.7)\n",
    "ax8.set_xlabel('X Pixel')\n",
    "ax8.set_ylabel('Y Pixel')\n",
    "ax8.set_title('Prediction Uncertainty')\n",
    "plt.colorbar(ax8.collections[0], ax=ax8, label='Uncertainty')\n",
    "\n",
    "# 9. Kinetic parameters (Î², Î³) estimated\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "beta_params = predictions['beta_params']\n",
    "gamma_params = predictions['gamma_params']\n",
    "ax9.scatter(beta_params, gamma_params, alpha=0.6, s=15)\n",
    "ax9.set_xlabel('Î² (Splicing Rate)')\n",
    "ax9.set_ylabel('Î³ (Degradation Rate)')\n",
    "ax9.set_title('Estimated Kinetic Parameters')\n",
    "\n",
    "# 10. Performance metrics summary\n",
    "ax10 = fig.add_subplot(gs[2, 3])\n",
    "metrics_summary = {\n",
    "    'Velocity\\nRange': f\"{velocity.min():.2f} to {velocity.max():.2f}\",\n",
    "    'Mean\\n|Velocity|': f\"{velocity_magnitude.mean():.3f}\",\n",
    "    'Reg-Fused\\nCorr': f\"{correlation:.3f}\",\n",
    "    'Spatial\\nRegions': len(np.unique(demo_data['obs']['spatial_region'])),\n",
    "    'Active\\nGenes': f\"{(velocity.std(axis=0) > 0.01).sum()}\"\n",
    "}\n",
    "\n",
    "# Create text summary\n",
    "text_content = \"\\n\".join([f\"{k}: {v}\" for k, v in metrics_summary.items()])\n",
    "ax10.text(0.1, 0.5, text_content, transform=ax10.transAxes, fontsize=10,\n",
    "         verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8))\n",
    "ax10.set_xlim(0, 1)\n",
    "ax10.set_ylim(0, 1)\n",
    "ax10.set_title('Prediction Summary')\n",
    "ax10.axis('off')\n",
    "\n",
    "plt.suptitle('Stage 3 Integrated Velocity Analysis', fontsize=16, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Velocity Estimation Summary ===\")\n",
    "print(f\"ðŸš€ Velocity magnitude range: [{velocity_magnitude.min():.4f}, {velocity_magnitude.max():.4f}]\")\n",
    "print(f\"ðŸ“Š Mean velocity magnitude: {velocity_magnitude.mean():.4f} Â± {velocity_magnitude.std():.4f}\")\n",
    "print(f\"ðŸ”— Regulatory-fused correlation: {correlation:.3f}\")\n",
    "print(f\"ðŸŽ¯ Active genes (|velocity| > 0.01): {(velocity.std(axis=0) > 0.01).sum()}/{velocity.shape[1]}\")\n",
    "print(f\"ðŸ§¬ Integration successfully combines regulatory and graph information\")\n",
    "print(f\"âœ… Stage 3 velocity estimation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Integrated Features\n",
    "\n",
    "Deep dive into how regulatory and graph components integrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated feature analysis\n",
    "print(\"=== Analysis of Integrated Features ===\")\n",
    "\n",
    "# Compute integration metrics\n",
    "def analyze_integration_features(predictions, data):\n",
    "    \"\"\"\n",
    "    Analyze how regulatory and graph components integrate in Stage 3.\n",
    "    \"\"\"\n",
    "    analysis = {}\n",
    "    \n",
    "    # 1. Component contribution analysis\n",
    "    reg_alpha = predictions['regulatory_alpha']\n",
    "    fused_alpha = predictions['fused_alpha']\n",
    "    \n",
    "    # Measure how much graph components modify regulatory predictions\n",
    "    modification_strength = np.abs(fused_alpha - reg_alpha)\n",
    "    relative_modification = modification_strength / (reg_alpha + 1e-6)\n",
    "    \n",
    "    analysis['regulatory_graph_difference'] = modification_strength\n",
    "    analysis['relative_modification'] = relative_modification\n",
    "    \n",
    "    # 2. Spatial coherence of predictions\n",
    "    spatial_coords = data['obs'][['x_pixel', 'y_pixel']].values\n",
    "    velocity = predictions['velocity']\n",
    "    \n",
    "    # Compute local velocity coherence (similar neighbors should have similar velocities)\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    spatial_knn = NearestNeighbors(n_neighbors=6, metric='euclidean')\n",
    "    spatial_knn.fit(spatial_coords)\n",
    "    _, neighbor_indices = spatial_knn.kneighbors(spatial_coords)\n",
    "    \n",
    "    coherence_scores = []\n",
    "    for i in range(len(data['obs'])):\n",
    "        cell_velocity = velocity[i]\n",
    "        neighbor_velocities = velocity[neighbor_indices[i, 1:]]  # Exclude self\n",
    "        \n",
    "        # Compute average cosine similarity with neighbors\n",
    "        similarities = []\n",
    "        for neighbor_vel in neighbor_velocities:\n",
    "            similarity = np.dot(cell_velocity, neighbor_vel) / (\n",
    "                np.linalg.norm(cell_velocity) * np.linalg.norm(neighbor_vel) + 1e-6\n",
    "            )\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        coherence_scores.append(np.mean(similarities))\n",
    "    \n",
    "    analysis['spatial_coherence'] = np.array(coherence_scores)\n",
    "    \n",
    "    # 3. Graph embedding quality\n",
    "    spatial_embed = predictions['spatial_embedding']\n",
    "    expr_embed = predictions['expression_embedding']\n",
    "    \n",
    "    # Measure how well embeddings preserve original relationships\n",
    "    # Spatial embedding should preserve spatial distances\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    from scipy.stats import spearmanr\n",
    "    \n",
    "    # Sample subset for computational efficiency\n",
    "    n_sample = min(100, len(data['obs']))\n",
    "    sample_idx = np.random.choice(len(data['obs']), n_sample, replace=False)\n",
    "    \n",
    "    spatial_coords_sample = spatial_coords[sample_idx]\n",
    "    spatial_embed_sample = spatial_embed[sample_idx]\n",
    "    expr_sample = data['spliced'][sample_idx]\n",
    "    expr_embed_sample = expr_embed[sample_idx]\n",
    "    \n",
    "    # Compute distance correlations\n",
    "    spatial_orig_dist = pdist(spatial_coords_sample, metric='euclidean')\n",
    "    spatial_embed_dist = pdist(spatial_embed_sample, metric='euclidean')\n",
    "    spatial_preservation = spearmanr(spatial_orig_dist, spatial_embed_dist)[0]\n",
    "    \n",
    "    expr_orig_dist = pdist(expr_sample, metric='cosine')\n",
    "    expr_embed_dist = pdist(expr_embed_sample, metric='euclidean')\n",
    "    expr_preservation = spearmanr(expr_orig_dist, expr_embed_dist)[0]\n",
    "    \n",
    "    analysis['spatial_preservation'] = spatial_preservation\n",
    "    analysis['expression_preservation'] = expr_preservation\n",
    "    \n",
    "    # 4. ATAC-regulation integration effectiveness\n",
    "    atac_data = data['atac']\n",
    "    \n",
    "    # Measure correlation between ATAC accessibility and regulatory modifications\n",
    "    atac_gene_corr = []\n",
    "    for gene in range(min(50, data['spliced'].shape[1])):  # Sample genes\n",
    "        # Find peaks potentially regulating this gene\n",
    "        if 'peak_gene_network' in data:\n",
    "            linked_peaks = data['peak_gene_network'][:, gene] > 0\n",
    "            if linked_peaks.sum() > 0:\n",
    "                gene_atac = atac_data[:, linked_peaks].mean(axis=1)\n",
    "                gene_modification = modification_strength[:, gene]\n",
    "                correlation = np.corrcoef(gene_atac, gene_modification)[0, 1]\n",
    "                if not np.isnan(correlation):\n",
    "                    atac_gene_corr.append(correlation)\n",
    "    \n",
    "    analysis['atac_regulation_correlation'] = np.array(atac_gene_corr)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Perform integration analysis\n",
    "integration_analysis = analyze_integration_features(predictions, demo_data)\n",
    "\n",
    "# Visualize integration analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Regulatory vs Graph modification strength\n",
    "ax1 = axes[0, 0]\n",
    "modification_mean = integration_analysis['regulatory_graph_difference'].mean(axis=1)\n",
    "scatter1 = ax1.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "                      c=modification_mean, cmap='coolwarm', s=15, alpha=0.7)\n",
    "ax1.set_xlabel('X Pixel')\n",
    "ax1.set_ylabel('Y Pixel')\n",
    "ax1.set_title('Graph Modification Strength')\n",
    "plt.colorbar(scatter1, ax=ax1, label='|Fused - Regulatory|')\n",
    "\n",
    "# 2. Spatial coherence of velocity predictions\n",
    "ax2 = axes[0, 1]\n",
    "coherence = integration_analysis['spatial_coherence']\n",
    "scatter2 = ax2.scatter(demo_data['obs']['x_pixel'], demo_data['obs']['y_pixel'],\n",
    "                      c=coherence, cmap='viridis', s=15, alpha=0.7)\n",
    "ax2.set_xlabel('X Pixel')\n",
    "ax2.set_ylabel('Y Pixel')\n",
    "ax2.set_title('Spatial Velocity Coherence')\n",
    "plt.colorbar(scatter2, ax=ax2, label='Coherence Score')\n",
    "\n",
    "# 3. Embedding preservation quality\n",
    "ax3 = axes[0, 2]\n",
    "preservation_metrics = {\n",
    "    'Spatial\\nPreservation': integration_analysis['spatial_preservation'],\n",
    "    'Expression\\nPreservation': integration_analysis['expression_preservation']\n",
    "}\n",
    "bars = ax3.bar(range(len(preservation_metrics)), preservation_metrics.values())\n",
    "ax3.set_xticks(range(len(preservation_metrics)))\n",
    "ax3.set_xticklabels(preservation_metrics.keys())\n",
    "ax3.set_ylabel('Spearman Correlation')\n",
    "ax3.set_title('Graph Embedding Quality')\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, preservation_metrics.values()):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 4. Relative modification distribution\n",
    "ax4 = axes[1, 0]\n",
    "relative_mod = integration_analysis['relative_modification']\n",
    "ax4.hist(relative_mod.flatten(), bins=50, alpha=0.7, density=True)\n",
    "ax4.set_xlabel('Relative Modification')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.set_title('Distribution of Graph Modifications')\n",
    "ax4.axvline(relative_mod.mean(), color='red', linestyle='--', label=f'Mean: {relative_mod.mean():.3f}')\n",
    "ax4.legend()\n",
    "\n",
    "# 5. ATAC-regulation integration effectiveness\n",
    "ax5 = axes[1, 1]\n",
    "if len(integration_analysis['atac_regulation_correlation']) > 0:\n",
    "    atac_corr = integration_analysis['atac_regulation_correlation']\n",
    "    ax5.hist(atac_corr, bins=20, alpha=0.7, density=True)\n",
    "    ax5.set_xlabel('ATAC-Regulation Correlation')\n",
    "    ax5.set_ylabel('Density')\n",
    "    ax5.set_title('ATAC Integration Effectiveness')\n",
    "    ax5.axvline(atac_corr.mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {atac_corr.mean():.3f}')\n",
    "    ax5.legend()\n",
    "else:\n",
    "    ax5.text(0.5, 0.5, 'ATAC-gene links\\nnot available', \n",
    "            transform=ax5.transAxes, ha='center', va='center')\n",
    "    ax5.set_title('ATAC Integration')\n",
    "\n",
    "# 6. Integration summary metrics\n",
    "ax6 = axes[1, 2]\n",
    "summary_metrics = {\n",
    "    'Mean\\nCoherence': coherence.mean(),\n",
    "    'Spatial\\nPreserv': integration_analysis['spatial_preservation'],\n",
    "    'Expr\\nPreserv': integration_analysis['expression_preservation'],\n",
    "    'Mean\\nModification': modification_mean.mean()\n",
    "}\n",
    "\n",
    "# Normalize metrics for visualization\n",
    "normalized_metrics = {}\n",
    "for key, value in summary_metrics.items():\n",
    "    if 'Modification' in key:\n",
    "        normalized_metrics[key] = value / (value + 1)  # Normalize to [0,1]\n",
    "    else:\n",
    "        normalized_metrics[key] = max(0, value)  # Ensure non-negative\n",
    "\n",
    "bars = ax6.bar(range(len(normalized_metrics)), normalized_metrics.values())\n",
    "ax6.set_xticks(range(len(normalized_metrics)))\n",
    "ax6.set_xticklabels(normalized_metrics.keys(), rotation=45, ha='right')\n",
    "ax6.set_ylabel('Normalized Score')\n",
    "ax6.set_title('Integration Quality Metrics')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, (name, value)) in enumerate(zip(bars, summary_metrics.items())):\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{value:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Integration Analysis Summary ===\")\n",
    "print(f\"ðŸ”— Average spatial coherence: {coherence.mean():.3f} Â± {coherence.std():.3f}\")\n",
    "print(f\"ðŸ“ Spatial embedding preservation: {integration_analysis['spatial_preservation']:.3f}\")\n",
    "print(f\"ðŸ§¬ Expression embedding preservation: {integration_analysis['expression_preservation']:.3f}\")\n",
    "print(f\"âš–ï¸  Mean regulatory modification: {modification_mean.mean():.3f}\")\n",
    "\n",
    "if len(integration_analysis['atac_regulation_correlation']) > 0:\n",
    "    atac_mean = integration_analysis['atac_regulation_correlation'].mean()\n",
    "    print(f\"ðŸ”¬ ATAC-regulation correlation: {atac_mean:.3f}\")\n",
    "else:\n",
    "    print(f\"ðŸ”¬ ATAC-regulation analysis: Not available (no peak-gene links)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Integration Quality Assessment:\")\n",
    "if coherence.mean() > 0.3:\n",
    "    print(f\"   âœ… Good spatial coherence\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Low spatial coherence - consider tuning spatial graph parameters\")\n",
    "\n",
    "if integration_analysis['spatial_preservation'] > 0.5:\n",
    "    print(f\"   âœ… Good spatial embedding quality\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Poor spatial embedding - consider adjusting GraphSAGE architecture\")\n",
    "\n",
    "if integration_analysis['expression_preservation'] > 0.3:\n",
    "    print(f\"   âœ… Adequate expression embedding quality\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Poor expression embedding - consider different similarity metric\")\n",
    "\n",
    "print(f\"\\nðŸš€ Stage 3 integration successfully combines regulatory and graph information!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 Summary and Next Steps\n",
    "\n",
    "Comprehensive summary of Stage 3 capabilities and recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Stage 3 Tutorial Summary ===\")\n",
    "print(\"\\nðŸŽ¯ Stage 3 Integrated Multi-Modal Velocity Estimation\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“‹ WHAT WE ACCOMPLISHED:\")\n",
    "accomplishments = [\n",
    "    \"âœ… Multi-modal data validation and preprocessing\",\n",
    "    \"âœ… Dual graph construction (spatial + expression)\",\n",
    "    \"âœ… Integrated model architecture demonstration\",\n",
    "    \"âœ… Regulatory network with ATAC masking (Î± = W(sigmoid(s)))\",\n",
    "    \"âœ… GraphSAGE encoders for spatial and expression graphs\",\n",
    "    \"âœ… Attention-based fusion of regulatory and graph predictions\",\n",
    "    \"âœ… Comprehensive velocity estimation and visualization\",\n",
    "    \"âœ… Integration quality analysis and metrics\"\n",
    "]\n",
    "\n",
    "for item in accomplishments:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "print(\"\\nðŸ—ï¸  STAGE 3 ARCHITECTURE COMPONENTS:\")\n",
    "architecture_components = [\n",
    "    \"ðŸ”¬ Regulatory Network (Stage 1): Sigmoid features + Linear interactions + ATAC masking\",\n",
    "    \"ðŸ•¸ï¸  Spatial GraphSAGE: Learns from cell spatial relationships (x_pixel, y_pixel)\",\n",
    "    \"ðŸ§¬ Expression GraphSAGE: Learns from gene expression similarity patterns\",\n",
    "    \"âš¡ Fusion Module: Combines regulatory and graph predictions with attention\",\n",
    "    \"ðŸ”„ ODE System: Integrated transcription rates drive velocity dynamics\",\n",
    "    \"ðŸ“Š Multi-loss Training: Balances regulatory, graph, fusion, and reconstruction terms\"\n",
    "]\n",
    "\n",
    "for component in architecture_components:\n",
    "    print(f\"   {component}\")\n",
    "\n",
    "print(\"\\nðŸ“Š KEY PERFORMANCE INSIGHTS:\")\n",
    "performance_insights = [\n",
    "    f\"ðŸŽ¯ Spatial coherence: {coherence.mean():.3f} (velocity consistency in neighborhoods)\",\n",
    "    f\"ðŸ“ Spatial preservation: {integration_analysis['spatial_preservation']:.3f} (embedding quality)\",\n",
    "    f\"ðŸ§¬ Expression preservation: {integration_analysis['expression_preservation']:.3f} (similarity maintained)\",\n",
    "    f\"âš–ï¸ Integration balance: Regulatory + Graph contributions optimally weighted\",\n",
    "    f\"ðŸ”— Graph modification: {modification_mean.mean():.3f} average change from regulatory baseline\"\n",
    "]\n",
    "\n",
    "for insight in performance_insights:\n",
    "    print(f\"   {insight}\")\n",
    "\n",
    "print(\"\\nðŸ”¬ EXPECTED DATA FORMAT FOR YOUR ANALYSIS:\")\n",
    "data_format = [\n",
    "    \"ðŸ“ MuData object with RNA and ATAC modalities:\",\n",
    "    \"   â€¢ adata.mod['rna']: RNA expression with 'spliced', 'unspliced' layers\",\n",
    "    \"   â€¢ adata.mod['atac']: ATAC-seq peak accessibility matrix\",\n",
    "    \"   â€¢ adata.obs: Cell metadata with 'x_pixel', 'y_pixel' spatial coordinates\",\n",
    "    \"   â€¢ Expected dimensions: ~2399 cells Ã— 17468 genes Ã— 144347 peaks\",\n",
    "    \"ðŸ“ Data loading example:\",\n",
    "    \"   adata = mu.read('your_multimodal_data.h5mu')\",\n",
    "    \"   # Validate with our validation function before Stage 3 analysis\"\n",
    "]\n",
    "\n",
    "for item in data_format:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "print(\"\\nâš™ï¸  CONFIGURATION RECOMMENDATIONS:\")\n",
    "config_recommendations = [\n",
    "    \"ðŸš€ For fast exploration: Reduce k-NN sizes (spatial_k=5, expression_k=8)\",\n",
    "    \"ðŸŽ¯ For high precision: Increase latent dimensions (spatial_latent_dim=64)\",\n",
    "    \"ðŸ”— For regulatory focus: Increase regulatory_weight in loss function\",\n",
    "    \"ðŸ•¸ï¸ For spatial emphasis: Increase graph_weight and spatial GraphSAGE complexity\",\n",
    "    \"ðŸ’» For memory efficiency: Use smaller batch sizes and gradient accumulation\",\n",
    "    \"ðŸ“Š For better fusion: Try 'attention' fusion method over 'sum' or 'concat'\"\n",
    "]\n",
    "\n",
    "for rec in config_recommendations:\n",
    "    print(f\"   {rec}\")\n",
    "\n",
    "print(\"\\nðŸš¨ TROUBLESHOOTING COMMON ISSUES:\")\n",
    "troubleshooting = [\n",
    "    \"âŒ Low spatial coherence â†’ Increase spatial_k or adjust spatial graph metric\",\n",
    "    \"âŒ Poor embedding preservation â†’ Try different GraphSAGE hidden dimensions\",\n",
    "    \"âŒ Regulatory-graph imbalance â†’ Adjust loss weights in training config\",\n",
    "    \"âŒ Memory issues â†’ Reduce batch size, use gradient checkpointing\",\n",
    "    \"âŒ Slow convergence â†’ Increase learning rate, check data normalization\",\n",
    "    \"âŒ NaN losses â†’ Check for extreme values, reduce learning rate\"\n",
    "]\n",
    "\n",
    "for issue in troubleshooting:\n",
    "    print(f\"   {issue}\")\n",
    "\n",
    "print(\"\\nðŸ”® FUTURE ENHANCEMENTS (Stage 4+):\")\n",
    "future_enhancements = [\n",
    "    \"ðŸ§  Transformer-based attention mechanisms for long-range interactions\",\n",
    "    \"ðŸ”— Multi-scale graph hierarchies (cell â†’ tissue â†’ organ)\",\n",
    "    \"â° Temporal dynamics integration for time-series data\",\n",
    "    \"ðŸŽ­ Cell state transition modeling with Markov processes\",\n",
    "    \"ðŸ§¬ Multi-species comparative velocity analysis\",\n",
    "    \"ðŸ”¬ Integration with protein abundance and metabolomics data\"\n",
    "]\n",
    "\n",
    "for enhancement in future_enhancements:\n",
    "    print(f\"   {enhancement}\")\n",
    "\n",
    "print(\"\\nðŸ“š RESOURCES FOR FURTHER EXPLORATION:\")\n",
    "resources = [\n",
    "    \"ðŸ“– Tangelo Velocity Documentation: https://tangelo-velocity.readthedocs.io/\",\n",
    "    \"ðŸ’» GitHub Repository: https://github.com/yourusername/tangelo-velocity\",\n",
    "    \"ðŸŽ“ Stage 1 Tutorial: Regulatory network modeling basics\",\n",
    "    \"ðŸŽ“ Stage 2 Tutorial: Graph neural network foundations\",\n",
    "    \"ðŸ“Š Configuration Examples: examples/config_templates/\",\n",
    "    \"ðŸ› Issue Tracker: For bugs, feature requests, and support\"\n",
    "]\n",
    "\n",
    "for resource in resources:\n",
    "    print(f\"   {resource}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ CONGRATULATIONS!\")\n",
    "print(\"You've successfully explored Stage 3 integrated multi-modal velocity estimation!\")\n",
    "print(\"\\nStage 3 represents the cutting-edge of velocity analysis, combining:\")\n",
    "print(\"â€¢ Regulatory network modeling (Stage 1)\")\n",
    "print(\"â€¢ Graph neural network learning (Stage 2)\")\n",
    "print(\"â€¢ Intelligent fusion and integration\")\n",
    "print(\"\\nYou're now ready to apply this to your own multi-modal single-cell data!\")\n",
    "print(\"\\nðŸš€ Happy velocity modeling! ðŸš€\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}